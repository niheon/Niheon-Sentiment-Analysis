{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M27qF7CTrBqc"
      },
      "source": [
        "# TASK #1: UNDERSTAND THE PROBLEM STATEMENT AND BUSINESS CASE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VbX0jYELZend"
      },
      "source": [
        "data source: https://www.kaggle.com/sid321axn/amazon-alexa-reviews/kernels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uAE6Icc0uylP"
      },
      "source": [
        "# TASK #2: IMPORT LIBRARIES AND DATASETS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G0dz1JI_dufy",
        "outputId": "7914f801-43db-4421-8194-2a62eef92c06"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: jupyterthemes in /usr/local/lib/python3.8/dist-packages (0.20.0)\n",
            "Requirement already satisfied: notebook>=5.6.0 in /usr/local/lib/python3.8/dist-packages (from jupyterthemes) (6.3.0)\n",
            "Requirement already satisfied: ipython>=5.4.1 in /usr/local/lib/python3.8/dist-packages (from jupyterthemes) (7.9.0)\n",
            "Requirement already satisfied: matplotlib>=1.4.3 in /usr/local/lib/python3.8/dist-packages (from jupyterthemes) (3.5.3)\n",
            "Requirement already satisfied: lesscpy>=0.11.2 in /usr/local/lib/python3.8/dist-packages (from jupyterthemes) (0.15.1)\n",
            "Requirement already satisfied: jupyter-core in /usr/local/lib/python3.8/dist-packages (from jupyterthemes) (5.2.0)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.8/dist-packages (from ipython>=5.4.1->jupyterthemes) (57.4.0)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.8/dist-packages (from ipython>=5.4.1->jupyterthemes) (4.8.0)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.8/dist-packages (from ipython>=5.4.1->jupyterthemes) (2.6.1)\n",
            "Requirement already satisfied: jedi>=0.10 in /usr/local/lib/python3.8/dist-packages (from ipython>=5.4.1->jupyterthemes) (0.18.2)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.8/dist-packages (from ipython>=5.4.1->jupyterthemes) (5.7.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.8/dist-packages (from ipython>=5.4.1->jupyterthemes) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.8/dist-packages (from ipython>=5.4.1->jupyterthemes) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit<2.1.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from ipython>=5.4.1->jupyterthemes) (2.0.10)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.8/dist-packages (from ipython>=5.4.1->jupyterthemes) (0.2.0)\n",
            "Requirement already satisfied: ply in /usr/local/lib/python3.8/dist-packages (from lesscpy>=0.11.2->jupyterthemes) (3.11)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=1.4.3->jupyterthemes) (4.38.0)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=1.4.3->jupyterthemes) (8.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.2.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=1.4.3->jupyterthemes) (3.0.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=1.4.3->jupyterthemes) (23.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=1.4.3->jupyterthemes) (1.22.4)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=1.4.3->jupyterthemes) (1.4.4)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=1.4.3->jupyterthemes) (0.11.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=1.4.3->jupyterthemes) (2.8.2)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.8/dist-packages (from notebook>=5.6.0->jupyterthemes) (0.2.0)\n",
            "Requirement already satisfied: nbformat in /usr/local/lib/python3.8/dist-packages (from notebook>=5.6.0->jupyterthemes) (5.7.3)\n",
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.8/dist-packages (from notebook>=5.6.0->jupyterthemes) (6.5.4)\n",
            "Requirement already satisfied: Send2Trash>=1.5.0 in /usr/local/lib/python3.8/dist-packages (from notebook>=5.6.0->jupyterthemes) (1.8.0)\n",
            "Requirement already satisfied: prometheus-client in /usr/local/lib/python3.8/dist-packages (from notebook>=5.6.0->jupyterthemes) (0.16.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.8/dist-packages (from notebook>=5.6.0->jupyterthemes) (3.1.2)\n",
            "Requirement already satisfied: jupyter-client>=5.3.4 in /usr/local/lib/python3.8/dist-packages (from notebook>=5.6.0->jupyterthemes) (6.1.12)\n",
            "Requirement already satisfied: tornado>=6.1 in /usr/local/lib/python3.8/dist-packages (from notebook>=5.6.0->jupyterthemes) (6.2)\n",
            "Requirement already satisfied: pyzmq>=17 in /usr/local/lib/python3.8/dist-packages (from notebook>=5.6.0->jupyterthemes) (23.2.1)\n",
            "Requirement already satisfied: argon2-cffi in /usr/local/lib/python3.8/dist-packages (from notebook>=5.6.0->jupyterthemes) (21.3.0)\n",
            "Requirement already satisfied: ipykernel in /usr/local/lib/python3.8/dist-packages (from notebook>=5.6.0->jupyterthemes) (5.3.4)\n",
            "Requirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.8/dist-packages (from notebook>=5.6.0->jupyterthemes) (0.13.3)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.8/dist-packages (from jupyter-core->jupyterthemes) (3.0.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.8/dist-packages (from jedi>=0.10->ipython>=5.4.1->jupyterthemes) (0.8.3)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.8/dist-packages (from prompt-toolkit<2.1.0,>=2.0.0->ipython>=5.4.1->jupyterthemes) (1.15.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.8/dist-packages (from prompt-toolkit<2.1.0,>=2.0.0->ipython>=5.4.1->jupyterthemes) (0.2.6)\n",
            "Requirement already satisfied: ptyprocess in /usr/local/lib/python3.8/dist-packages (from terminado>=0.8.3->notebook>=5.6.0->jupyterthemes) (0.7.0)\n",
            "Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.8/dist-packages (from argon2-cffi->notebook>=5.6.0->jupyterthemes) (21.2.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.8/dist-packages (from jinja2->notebook>=5.6.0->jupyterthemes) (2.1.2)\n",
            "Requirement already satisfied: nbclient>=0.5.0 in /usr/local/lib/python3.8/dist-packages (from nbconvert->notebook>=5.6.0->jupyterthemes) (0.7.2)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.8/dist-packages (from nbconvert->notebook>=5.6.0->jupyterthemes) (6.0.0)\n",
            "Requirement already satisfied: tinycss2 in /usr/local/lib/python3.8/dist-packages (from nbconvert->notebook>=5.6.0->jupyterthemes) (1.2.1)\n",
            "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.8/dist-packages (from nbconvert->notebook>=5.6.0->jupyterthemes) (0.4)\n",
            "Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.8/dist-packages (from nbconvert->notebook>=5.6.0->jupyterthemes) (0.2.2)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.8/dist-packages (from nbconvert->notebook>=5.6.0->jupyterthemes) (0.7.1)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.8/dist-packages (from nbconvert->notebook>=5.6.0->jupyterthemes) (0.8.4)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.8/dist-packages (from nbconvert->notebook>=5.6.0->jupyterthemes) (1.5.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.8/dist-packages (from nbconvert->notebook>=5.6.0->jupyterthemes) (4.6.3)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.8/dist-packages (from nbconvert->notebook>=5.6.0->jupyterthemes) (4.9.2)\n",
            "Requirement already satisfied: fastjsonschema in /usr/local/lib/python3.8/dist-packages (from nbformat->notebook>=5.6.0->jupyterthemes) (2.16.3)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.8/dist-packages (from nbformat->notebook>=5.6.0->jupyterthemes) (4.3.3)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.8/dist-packages (from jsonschema>=2.6->nbformat->notebook>=5.6.0->jupyterthemes) (22.2.0)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.8/dist-packages (from jsonschema>=2.6->nbformat->notebook>=5.6.0->jupyterthemes) (0.19.3)\n",
            "Requirement already satisfied: importlib-resources>=1.4.0 in /usr/local/lib/python3.8/dist-packages (from jsonschema>=2.6->nbformat->notebook>=5.6.0->jupyterthemes) (5.12.0)\n",
            "Requirement already satisfied: cffi>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from argon2-cffi-bindings->argon2-cffi->notebook>=5.6.0->jupyterthemes) (1.15.1)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.8/dist-packages (from bleach->nbconvert->notebook>=5.6.0->jupyterthemes) (0.5.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.8/dist-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook>=5.6.0->jupyterthemes) (2.21)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.8/dist-packages (from importlib-resources>=1.4.0->jsonschema>=2.6->nbformat->notebook>=5.6.0->jupyterthemes) (3.15.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install jupyterthemes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YBp2qDPb8pDo",
        "outputId": "431474b2-87e9-40d3-ca1b-5c06cf1a48d7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import nltk\n",
        "from jupyterthemes import jtplot\n",
        "jtplot.style(theme='monokai', context='notebook', ticks=True, grid=False) \n",
        "# setting the style of the notebook to be monokai theme  \n",
        "# this line of code is important to ensure that we are able to see the x and y axes clearly\n",
        "# If you don't run this code line, you will notice that the xlabel and ylabel on any plot is black on black and it will be hard to see them. \n",
        "#import libraries \n",
        "import re\n",
        "import string\n",
        "import nltk\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.stem.wordnet import WordNetLemmatizer\n",
        "import spacy\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "from nltk.corpus import stopwords\n",
        "stop = stopwords.words('english')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9i8D2TW7c-Lb",
        "outputId": "85131131-cec7-443d-f2d9-42b1dc9a09eb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "#connect to google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive') "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "tjIiJdM4u1IE",
        "outputId": "e16e4317-1b55-4fa7-add6-fd0211b147e6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      rating       date         variation  \\\n",
              "0          5  31-Jul-18  Charcoal Fabric    \n",
              "1          5  31-Jul-18  Charcoal Fabric    \n",
              "2          4  31-Jul-18    Walnut Finish    \n",
              "3          5  31-Jul-18  Charcoal Fabric    \n",
              "4          5  31-Jul-18  Charcoal Fabric    \n",
              "...      ...        ...               ...   \n",
              "3145       5  30-Jul-18        Black  Dot   \n",
              "3146       5  30-Jul-18        Black  Dot   \n",
              "3147       5  30-Jul-18        Black  Dot   \n",
              "3148       5  30-Jul-18        White  Dot   \n",
              "3149       4  29-Jul-18        Black  Dot   \n",
              "\n",
              "                                       verified_reviews  feedback  \n",
              "0                                         Love my Echo!         1  \n",
              "1                                             Loved it!         1  \n",
              "2     Sometimes while playing a game, you can answer...         1  \n",
              "3     I have had a lot of fun with this thing. My 4 ...         1  \n",
              "4                                                 Music         1  \n",
              "...                                                 ...       ...  \n",
              "3145  Perfect for kids, adults and everyone in betwe...         1  \n",
              "3146  Listening to music, searching locations, check...         1  \n",
              "3147  I do love these things, i have them running my...         1  \n",
              "3148  Only complaint I have is that the sound qualit...         1  \n",
              "3149                                               Good         1  \n",
              "\n",
              "[3150 rows x 5 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f3b8ca1f-db75-492f-945c-bb5a7a84331e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>rating</th>\n",
              "      <th>date</th>\n",
              "      <th>variation</th>\n",
              "      <th>verified_reviews</th>\n",
              "      <th>feedback</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5</td>\n",
              "      <td>31-Jul-18</td>\n",
              "      <td>Charcoal Fabric</td>\n",
              "      <td>Love my Echo!</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5</td>\n",
              "      <td>31-Jul-18</td>\n",
              "      <td>Charcoal Fabric</td>\n",
              "      <td>Loved it!</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4</td>\n",
              "      <td>31-Jul-18</td>\n",
              "      <td>Walnut Finish</td>\n",
              "      <td>Sometimes while playing a game, you can answer...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>5</td>\n",
              "      <td>31-Jul-18</td>\n",
              "      <td>Charcoal Fabric</td>\n",
              "      <td>I have had a lot of fun with this thing. My 4 ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>31-Jul-18</td>\n",
              "      <td>Charcoal Fabric</td>\n",
              "      <td>Music</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3145</th>\n",
              "      <td>5</td>\n",
              "      <td>30-Jul-18</td>\n",
              "      <td>Black  Dot</td>\n",
              "      <td>Perfect for kids, adults and everyone in betwe...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3146</th>\n",
              "      <td>5</td>\n",
              "      <td>30-Jul-18</td>\n",
              "      <td>Black  Dot</td>\n",
              "      <td>Listening to music, searching locations, check...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3147</th>\n",
              "      <td>5</td>\n",
              "      <td>30-Jul-18</td>\n",
              "      <td>Black  Dot</td>\n",
              "      <td>I do love these things, i have them running my...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3148</th>\n",
              "      <td>5</td>\n",
              "      <td>30-Jul-18</td>\n",
              "      <td>White  Dot</td>\n",
              "      <td>Only complaint I have is that the sound qualit...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3149</th>\n",
              "      <td>4</td>\n",
              "      <td>29-Jul-18</td>\n",
              "      <td>Black  Dot</td>\n",
              "      <td>Good</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3150 rows × 5 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f3b8ca1f-db75-492f-945c-bb5a7a84331e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f3b8ca1f-db75-492f-945c-bb5a7a84331e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f3b8ca1f-db75-492f-945c-bb5a7a84331e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 99
        }
      ],
      "source": [
        "# Load the data\n",
        "reviews_df = pd.read_csv('/content/drive/MyDrive/Dash_plotly_home/amazon_reviews.csv') #you should change the path \n",
        "reviews_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZQgT-Nfgseyr",
        "outputId": "4086c795-5a24-4f62-b88b-d40ff48a7976"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    2893\n",
              "0     257\n",
              "Name: feedback, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 100
        }
      ],
      "source": [
        "reviews_df['feedback'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mYDXT5GCP-JN"
      },
      "outputs": [],
      "source": [
        "# Load spacy\n",
        "nlp = spacy.load('en_core_web_sm')\n",
        "\n",
        "def clean_string(text, stem=\"None\"):\n",
        "\n",
        "    final_string = \"\"\n",
        "\n",
        "    # Make lower\n",
        "    text = text.lower()\n",
        "\n",
        "    # Remove line breaks\n",
        "    text = re.sub(r'\\n', '', text)\n",
        "    \n",
        "\n",
        "    # Remove puncuation\n",
        "    translator = str.maketrans('', '', string.punctuation)\n",
        "    text = text.translate(translator)\n",
        "\n",
        "    # Remove stop words\n",
        "    text = text.split()\n",
        "    \n",
        "    useless_words = ['hi', 'im']\n",
        "\n",
        "    text_filtered = [word for word in text if not word in useless_words]\n",
        "\n",
        "    # Remove numbers\n",
        "    text_filtered = [re.sub(r'\\w*\\d\\w*', '', w) for w in text_filtered]\n",
        "\n",
        "\n",
        "    if stem == 'Lem':\n",
        "        lem = WordNetLemmatizer()\n",
        "        text_stemmed = [lem.lemmatize(y) for y in text_filtered]\n",
        "\n",
        "    final_string = ' '.join(text_stemmed)\n",
        "\n",
        "    return final_string"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lPlnXPNcQLQL"
      },
      "outputs": [],
      "source": [
        "reviews_df['verified_reviews'] = reviews_df['verified_reviews'].apply(lambda x: clean_string(x, stem='Lem')) #apply the function clean_string\n",
        "reviews_df['verified_reviews'] = reviews_df['verified_reviews'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop)])) #remove stop words from the column. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wQG98HB4sBbu"
      },
      "outputs": [],
      "source": [
        "#reviews_df['variation'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RUt2ON_UxyYk"
      },
      "outputs": [],
      "source": [
        "# View the DataFrame Information\n",
        "#reviews_df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "inykIwB6Yl9k"
      },
      "outputs": [],
      "source": [
        "import pandas as pd   #create the Date receiced column that will be used later in the dashbboard\n",
        "reviews_df['Date received'] = pd.to_datetime(reviews_df['date'].str.strip(), infer_datetime_format=True)\n",
        "reviews_df['Date received'] = pd.to_datetime(reviews_df['Date received'].dt.strftime('%m-%d-%Y'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iVpCkXX7kRJ_",
        "outputId": "d57fbba3-31a2-4498-ba7d-d98754fdd015"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Timestamp('2018-07-31 00:00:00')"
            ]
          },
          "metadata": {},
          "execution_count": 106
        }
      ],
      "source": [
        "min_date = reviews_df[\"Date received\"].min()\n",
        "max_date = reviews_df[\"Date received\"].max()\n",
        "max_date\n",
        "#these values will be used later in the dashboard"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q5O4Mh9vZIyN"
      },
      "outputs": [],
      "source": [
        "#reviews_df  # format=\"%m/%d/%Y\" #this format is required in the dash"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hMq3-KWOx0e1"
      },
      "outputs": [],
      "source": [
        "# View DataFrame Statistical Summary\n",
        "#reviews_df.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xF-c5PBBcgsP"
      },
      "source": [
        "**MINI CHALLENGE #1:** \n",
        "- **Drop the 'date' column from the DataFrame** \n",
        "- **Ensure that the column has been succesfully dropped** "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0or3Bf7ZcgsR"
      },
      "outputs": [],
      "source": [
        "reviews_df = reviews_df.drop(['date'], axis=1)\n",
        "#reviews_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5w38gvjrQpHT"
      },
      "source": [
        "# Bigram Part"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0RFnMuRMQwXr",
        "outputId": "baae706f-a833-47c9-d2a4-f98249097d20"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-110-74279bd3728f>:6: FutureWarning:\n",
            "\n",
            "Columnar iteration over characters will be deprecated in future releases.\n",
            "\n",
            "<ipython-input-110-74279bd3728f>:31: FutureWarning:\n",
            "\n",
            "The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
            "\n",
            "<ipython-input-110-74279bd3728f>:32: FutureWarning:\n",
            "\n",
            "The default value of regex will change from True to False in a future version.\n",
            "\n",
            "<ipython-input-110-74279bd3728f>:33: FutureWarning:\n",
            "\n",
            "The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#bigrams_EDA , cleaning for the bigram extraction task\n",
        "bigram_freq = lambda s: list(nltk.FreqDist(nltk.bigrams(s.split(\" \"))).items())\n",
        "reviewss_df = reviews_df.copy()\n",
        "reviewss_df['bigrams']= reviewss_df['verified_reviews'].apply(bigram_freq)\n",
        "reviewss_df =reviewss_df.explode('bigrams')\n",
        "reviewss_df['bigram'], reviewss_df['b'] = reviewss_df.bigrams.str\n",
        "\n",
        "def remove_emojis(data):\n",
        "    emoj = re.compile(\"[\"\n",
        "        u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
        "        u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
        "        u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
        "        u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
        "        u\"\\U00002500-\\U00002BEF\"  # chinese char\n",
        "        u\"\\U00002702-\\U000027B0\"\n",
        "        u\"\\U00002702-\\U000027B0\"\n",
        "        u\"\\U000024C2-\\U0001F251\"\n",
        "        u\"\\U0001f926-\\U0001f937\"\n",
        "        u\"\\U00010000-\\U0010ffff\"\n",
        "        u\"\\u2640-\\u2642\" \n",
        "        u\"\\u2600-\\u2B55\"\n",
        "        u\"\\u200d\"\n",
        "        u\"\\u23cf\"\n",
        "        u\"\\u23e9\"\n",
        "        u\"\\u231a\"\n",
        "        u\"\\ufe0f\"  # dingbats\n",
        "        u\"\\u3030\" \"]+\", re.UNICODE)\n",
        "    return re.sub(emoj, '', str(data)) \n",
        "\n",
        "reviewss_df['bigram'] = reviewss_df.apply(lambda x: remove_emojis(x.bigram), axis=1)\n",
        "reviewss_df['bigram'] = reviewss_df['bigram'].astype(str).str.replace(\"(\", \"\")\n",
        "reviewss_df['bigram'] = reviewss_df['bigram'].astype(str).str.replace(\"[!@#$]\", \"\") \n",
        "reviewss_df['bigram'] = reviewss_df['bigram'].astype(str).str.replace(\")\", \"\")\n",
        "reviewss_df['bigram'] = reviewss_df['bigram'].astype(str).str.replace(\"'\", \"\")\n",
        "reviewss_df['bigram'] = reviewss_df['bigram'].astype(str).str.replace(\"'\", \"\")\n",
        "reviewss_df['bigram'] = reviewss_df['bigram'].astype(str).str.replace(\",\", \"_\")\n",
        "reviewss_df['bigram'] = reviewss_df['bigram'].astype(str).str.replace(\"_ \", \"_\")\n",
        "reviewss_df['bigram'] = reviewss_df['bigram'].astype(str).str.replace(\" _\", \"_\")\n",
        "del reviewss_df['b']\n",
        "bigram_df =reviewss_df.groupby(['bigram','variation']).size().reset_index() \n",
        "bigram_df = bigram_df.rename(columns={0: 'value', 'variation': 'company','bigram':'ngram'})# the output is a dataframe with bigrams grouped by varitation with count. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "dJZJBoDlRo1a",
        "outputId": "d6f9a579-d807-4c8a-cfe5-77b0370b9b4d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                ngram           company  value\n",
              "0             _course       Black  Plus      1\n",
              "1           _download       Black  Spot      1\n",
              "2            _haven’t       Black  Spot      1\n",
              "3               _love       Black  Spot      1\n",
              "4               _much             Black      1\n",
              "...               ...               ...    ...\n",
              "27074  “white”_option       White  Show      1\n",
              "27075    “your”_music  Charcoal Fabric       2\n",
              "27076         ”_alexa       Black  Spot      1\n",
              "27077          ”_good       Black  Spot      1\n",
              "27078         ⏰_music       Black  Spot      1\n",
              "\n",
              "[27079 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-02a300a2-a17f-4d15-86cd-9321d0049f21\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ngram</th>\n",
              "      <th>company</th>\n",
              "      <th>value</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>_course</td>\n",
              "      <td>Black  Plus</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>_download</td>\n",
              "      <td>Black  Spot</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>_haven’t</td>\n",
              "      <td>Black  Spot</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>_love</td>\n",
              "      <td>Black  Spot</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>_much</td>\n",
              "      <td>Black</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27074</th>\n",
              "      <td>“white”_option</td>\n",
              "      <td>White  Show</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27075</th>\n",
              "      <td>“your”_music</td>\n",
              "      <td>Charcoal Fabric</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27076</th>\n",
              "      <td>”_alexa</td>\n",
              "      <td>Black  Spot</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27077</th>\n",
              "      <td>”_good</td>\n",
              "      <td>Black  Spot</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27078</th>\n",
              "      <td>⏰_music</td>\n",
              "      <td>Black  Spot</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>27079 rows × 3 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-02a300a2-a17f-4d15-86cd-9321d0049f21')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-02a300a2-a17f-4d15-86cd-9321d0049f21 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-02a300a2-a17f-4d15-86cd-9321d0049f21');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 111
        }
      ],
      "source": [
        "bigram_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vIGixpQGRjFc"
      },
      "outputs": [],
      "source": [
        "bigram_df = bigram_df[bigram_df.ngram != '_']\n",
        "bigram_df = bigram_df[bigram_df.ngram != '_a']\n",
        "bigram_df = bigram_df[bigram_df.ngram != '_not']\n",
        "bigram_df = bigram_df[bigram_df.ngram != '_and']\n",
        "bigram_df = bigram_df[bigram_df.ngram != ' _not']\n",
        "bigram_df = bigram_df[bigram_df.ngram != ' _and']\n",
        "bigram_df = bigram_df[bigram_df.ngram != ' _are']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nggXoVMLRkZr"
      },
      "outputs": [],
      "source": [
        "#cleanning \n",
        "bigram_df = bigram_df[bigram_df.ngram != 'nan']\n",
        "bigram_df['ngram'] = bigram_df['ngram'].astype(str).str.replace(\"—\", \" \")\n",
        "bigram_df['ngram'] = bigram_df['ngram'].astype(str).str.replace(\"“\", \" \")\n",
        "bigram_df['ngram'] = bigram_df['ngram'].astype(str).str.replace(\"‘\", \" \")\n",
        "bigram_df['ngram'] = bigram_df['ngram'].astype(str).str.replace(\"’\", \" \")\n",
        "bigram_df['ngram'] = bigram_df['ngram'].astype(str).str.replace(\" \", \"\")\n",
        "bigram_df['ngram'] = bigram_df['ngram'].astype(str).str.replace(\"”\", \" \")\n",
        "#bigram_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 739
        },
        "id": "vBuQtezWRmEC",
        "outputId": "a5b93f4d-d983-4ba7-b9b1-b257cd1cffe7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "               bigram  count  words\n",
              "19683      turn_light     13     13\n",
              "5511         echo_dot     13     13\n",
              "18237  still_learning     13     13\n",
              "11367       love_echo     13     13\n",
              "21911       work_well     13     13\n",
              "5454         easy_set     13     13\n",
              "21836      work_great     13     13\n",
              "20810         wa_easy     12     12\n",
              "8216    great_product     12     12\n",
              "14070      play_music     12     12\n",
              "8182       great_love     12     12\n",
              "17619   sound_quality     12     12\n",
              "11325      love_alexa     12     12\n",
              "8242      great_sound     11     11\n",
              "14516       prime_day     11     11\n",
              "14123   playing_music     11     11\n",
              "1061     amazon_prime     10     10\n",
              "1051     amazon_music     10     10\n",
              "6064      even_though     10     10\n",
              "10962    listen_music     10     10\n",
              "5047        dont_know     10     10\n",
              "12204     much_better     10     10"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-dc31acde-91e9-4328-bb29-d9534b7d715a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>bigram</th>\n",
              "      <th>count</th>\n",
              "      <th>words</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>19683</th>\n",
              "      <td>turn_light</td>\n",
              "      <td>13</td>\n",
              "      <td>13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5511</th>\n",
              "      <td>echo_dot</td>\n",
              "      <td>13</td>\n",
              "      <td>13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18237</th>\n",
              "      <td>still_learning</td>\n",
              "      <td>13</td>\n",
              "      <td>13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11367</th>\n",
              "      <td>love_echo</td>\n",
              "      <td>13</td>\n",
              "      <td>13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21911</th>\n",
              "      <td>work_well</td>\n",
              "      <td>13</td>\n",
              "      <td>13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5454</th>\n",
              "      <td>easy_set</td>\n",
              "      <td>13</td>\n",
              "      <td>13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21836</th>\n",
              "      <td>work_great</td>\n",
              "      <td>13</td>\n",
              "      <td>13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20810</th>\n",
              "      <td>wa_easy</td>\n",
              "      <td>12</td>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8216</th>\n",
              "      <td>great_product</td>\n",
              "      <td>12</td>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14070</th>\n",
              "      <td>play_music</td>\n",
              "      <td>12</td>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8182</th>\n",
              "      <td>great_love</td>\n",
              "      <td>12</td>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17619</th>\n",
              "      <td>sound_quality</td>\n",
              "      <td>12</td>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11325</th>\n",
              "      <td>love_alexa</td>\n",
              "      <td>12</td>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8242</th>\n",
              "      <td>great_sound</td>\n",
              "      <td>11</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14516</th>\n",
              "      <td>prime_day</td>\n",
              "      <td>11</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14123</th>\n",
              "      <td>playing_music</td>\n",
              "      <td>11</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1061</th>\n",
              "      <td>amazon_prime</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1051</th>\n",
              "      <td>amazon_music</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6064</th>\n",
              "      <td>even_though</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10962</th>\n",
              "      <td>listen_music</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5047</th>\n",
              "      <td>dont_know</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12204</th>\n",
              "      <td>much_better</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-dc31acde-91e9-4328-bb29-d9534b7d715a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-dc31acde-91e9-4328-bb29-d9534b7d715a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-dc31acde-91e9-4328-bb29-d9534b7d715a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 114
        }
      ],
      "source": [
        "embed_df = bigram_df.copy()   #embed_df will be used later in the dashboard, is just a groupby dataframe \n",
        "#embed_df = embed_df.ngram.value_counts()\n",
        "embed_df = embed_df.groupby('ngram').count().reset_index()\n",
        "embed_df = embed_df.sort_values(\n",
        "   by=\"company\",\n",
        "    ascending=False\n",
        ")\n",
        "embed_df = embed_df.rename(columns={'ngram': 'bigram', 'company': 'count','value':'words'}) #just remaining for the dashboard\n",
        "embed_df = embed_df.iloc[:22]  #take only the 21 most frequent bigrams that will be plotted in the dashboard later\n",
        "embed_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LlszUhNNyrl_"
      },
      "source": [
        "# TASK #3: PERFORM DATA VISUALIZATION"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a5-E_d3SbEKV"
      },
      "outputs": [],
      "source": [
        "#reviews_df['variation'].value_counts()\n",
        "# Check for missing values\n",
        "#reviews_df.isnull()\n",
        "# Check for missing with a heatmap to confirm\n",
        "#sns.heatmap(reviews_df.isnull(), yticklabels = False)\n",
        "# Plot the count plot for the ratings \n",
        "#sns.countplot(x = reviews_df['rating'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "giHTz0a0cgsq"
      },
      "source": [
        "**MINI CHALLENGE #2:** \n",
        "- **Plot the countplot for the feedback column**\n",
        "- **Roughly how many positive and negative feedback are present in the dataset?**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MdThwC21cgsr"
      },
      "outputs": [],
      "source": [
        "# Plot the count plot for the feedback\n",
        "#sns.countplot(x = reviews_df['feedback'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6txq0KIGcgsu"
      },
      "source": [
        "# TASK #4: PERFORM DATA EXPLORATION"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZiVkQqEPMDDD"
      },
      "outputs": [],
      "source": [
        "# Get the length of characters for each verfied review\n",
        "reviews_df['length'] = (reviews_df['verified_reviews']).apply(len)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RYLqq7WetK79"
      },
      "outputs": [],
      "source": [
        "# Plot the histogram for the length\n",
        "#reviews_df['length'].plot(bins = 100, kind = 'hist')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NECH94w1KSpS"
      },
      "outputs": [],
      "source": [
        "# Let's see the longest message \n",
        "#reviews_df[reviews_df['length'] == 2851]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3x0YGkgCcgs3"
      },
      "outputs": [],
      "source": [
        "# Grab only the verified reviews column and show the first element\n",
        "#reviews_df[reviews_df['length'] == 2851]['verified_reviews'].iloc[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qCKQWNMPcgs4"
      },
      "source": [
        "**MINI CHALLENGE #3:**\n",
        "- **View the message with the average length**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "vVVjj38mcgs5",
        "outputId": "e01f7270-4624-4988-ad72-2640c1229d8c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'work replaced expired bedside radioalarmit took realize option setting involved using touch screenmaybe said something setup process'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 121
        }
      ],
      "source": [
        "# View the message with the average length\n",
        "reviews_df[reviews_df['length'] == 132]['verified_reviews'].iloc[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vU40bQACcgs6"
      },
      "source": [
        "# TASK #5: PLOT THE WORDCLOUD"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5d38HsgdA3LA"
      },
      "outputs": [],
      "source": [
        "# Obtain only the positive reviews\n",
        "positive = reviews_df[reviews_df['feedback']==1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cv3wJuaEBNaX"
      },
      "outputs": [],
      "source": [
        "# Obtain the negative reviews only\n",
        "negative = reviews_df[reviews_df['feedback']==0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gPBOCIbxCCKE"
      },
      "outputs": [],
      "source": [
        "# Convert to list format\n",
        "sentences = positive['verified_reviews'].tolist()\n",
        "#len(sentences)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4V3vfaX9Cbgr"
      },
      "outputs": [],
      "source": [
        "# Join all reviews into one large string\n",
        "sentences_as_one_string = ' '.join(sentences)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2GVjDXBFCK7_",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "from wordcloud import WordCloud\n",
        "\n",
        "#plt.figure(figsize=(20,20))\n",
        "#plt.imshow(WordCloud().generate(sentences_as_one_string))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IjoOWfzYcgtB"
      },
      "source": [
        "**MINI CHALLENGE #4:** \n",
        "- **Plot the wordcloud of the \"negative\" dataframe** \n",
        "- **What do you notice? Does the data make sense?**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nf3yPx0mcgtC"
      },
      "outputs": [],
      "source": [
        "# Plot the wordcloud of the \"negative\" dataframe\n",
        "sentences = negative['verified_reviews'].tolist() # Convert to list format\n",
        "sentences_as_one_string = ' '.join(sentences)\n",
        "#plt.figure(figsize=(20,20))\n",
        "#plt.imshow(WordCloud().generate(sentences_as_one_string))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y0GmpAjG3GiH"
      },
      "source": [
        "# TASK #6: TEXT DATA CLEANING 101"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "lrET3QD4cgtE",
        "outputId": "6e0dda70-c928-4699-d10f-0cb85a90dbc1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 128
        }
      ],
      "source": [
        "import string\n",
        "string.punctuation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JG4ddkfacgtF"
      },
      "outputs": [],
      "source": [
        "Test = '$I Love Coursera &Rhyme Guided Projects...!!!!'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_2EewIUSPIHJ"
      },
      "outputs": [],
      "source": [
        "Test_punc_removed = [char for char in Test if char not in string.punctuation]\n",
        "#Test_punc_removed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EMWeHpqNPIJ4"
      },
      "outputs": [],
      "source": [
        "# Join the characters again to form the string.\n",
        "Test_punc_removed_join = ''.join(Test_punc_removed)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f_juuvbOcgtH"
      },
      "outputs": [],
      "source": [
        "import nltk # Natural Language tool kit "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gA257fmTcgtI",
        "outputId": "44145f5b-134d-4e8d-eabe-a0043170a47b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "# You have to download stopwords Package to execute this command\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "stopwords.words('english')\n",
        "STOPWORDS = stopwords.words('english') #used in the dash plotly\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3lzUfHhtcgtI"
      },
      "outputs": [],
      "source": [
        "Test_punc_removed_join = 'I have been enjoying these coding, programming and AI guided Projects on Rhyme and Coursera'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u-D-mfoVcgtJ"
      },
      "outputs": [],
      "source": [
        "Test_punc_removed_join_clean = [word for word in Test_punc_removed_join.split() if word.lower() not in stopwords.words('english')]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xGE9PXmDcgtK"
      },
      "source": [
        "**MINI CHALLENGE #5:** \n",
        "- **For the following text, create a pipeline to remove punctuations followed by removing stopwords and test the pipeline**\n",
        "- **mini_challenge = 'Here is a mini challenge, that will teach you how to remove stopwords and punctuations from text..!!'**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3aPk-w2WPfYI"
      },
      "outputs": [],
      "source": [
        "mini_challenge = 'Here is a mini challenge, that will teach you how to remove stopwords and punctuations from text..!!'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hDfGKwMddTCF"
      },
      "outputs": [],
      "source": [
        "import string"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QWXE2ojXQ6F9"
      },
      "outputs": [],
      "source": [
        "challege = [ char for char in mini_challenge  if char not in string.punctuation ]\n",
        "challenge = ''.join(challege)\n",
        "challenge = [  word for word in challenge.split() if word.lower() not in stopwords.words('english')  ] \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TH3CvoVdTdOZ"
      },
      "source": [
        "# TASK #7-1: PERFORM TFIDF VECTORIZATION (TOKENIZATION)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LKcKPF7tTf0h",
        "outputId": "47f6d311-e973-48e3-b724-b3944594f48e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[  0  73]\n",
            " [  0 715]]\n",
            "0.5\n"
          ]
        }
      ],
      "source": [
        "import pickle\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics import confusion_matrix, roc_auc_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "features_train, features_test, labels_train, labels_test = train_test_split(\n",
        "    reviews_df['verified_reviews'], reviews_df['feedback'], random_state=42)\n",
        "# Using TF-IDF Vectorizer\n",
        "vect = TfidfVectorizer().fit(features_train)\n",
        "\n",
        "features_train_vectorized = vect.transform(features_train)\n",
        "\n",
        "model = LogisticRegression()\n",
        "model.fit(features_train_vectorized, labels_train)\n",
        "\n",
        "predictions = model.predict(vect.transform(features_test))\n",
        "\n",
        "print(confusion_matrix(labels_test, predictions))\n",
        "\n",
        "print(roc_auc_score(labels_test, predictions))\n",
        "\n",
        "pkl_filename = '/content/drive/MyDrive/Dash_plotly_home/trained_model.pkl'\n",
        "vocab_filename = '/content/drive/MyDrive/Dash_plotly_home/vocab.pkl'\n",
        "\n",
        "# Writing model to pickle file\n",
        "with open(pkl_filename, 'wb') as file:\n",
        "    pickle.dump(model, file)\n",
        "\n",
        "# Saving TF-IDF vocabulary\n",
        "with open(vocab_filename, 'wb') as file:\n",
        "    pickle.dump(vect.vocabulary_, file)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Kxb4M0pRBkU"
      },
      "source": [
        "# TASK #7-2: PERFORM COUNT VECTORIZATION (TOKENIZATION)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bRstHzLkRMxA"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "sample_data = ['This is the first paper.','This document is the second paper.','And this is the third one.','Is this the first paper?']\n",
        "vectorizer = CountVectorizer()\n",
        "X = vectorizer.fit_transform(sample_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ETXTPf_ocgtQ"
      },
      "source": [
        "**MINI CHALLENGE #6:**\n",
        "- **Without doing any code, perform count vectorization for the following list:**\n",
        "    -  mini_challenge = ['Hello World','Hello Hello World','Hello World world world']\n",
        "- **Confirm your answer with code**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EZKZCr_ERSl7"
      },
      "outputs": [],
      "source": [
        "mini_challenge = ['Hello World','Hello Hello World','Hello World world world']\n",
        "vectorizer_challenge = CountVectorizer()\n",
        "X_challenge = vectorizer.fit_transform(mini_challenge)\n",
        "#print(X_challenge.toarray())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2geMzGITbZPJ"
      },
      "source": [
        "# TASK #8: CREATE A PIPELINE TO REMOVE PUNCTUATIONS, STOPWORDS AND PERFORM COUNT VECTORIZATION"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WHJnbIDeSmlm"
      },
      "outputs": [],
      "source": [
        "# Let's define a pipeline to clean up all the messages \n",
        "# The pipeline performs the following: (1) remove punctuation, (2) remove stopwords\n",
        "\n",
        "def process_text(text):\n",
        "    test_punc_removed = [char for char in text if char not in string.punctuation]\n",
        "    test_punc_removed = ''.join(test_punc_removed)\n",
        "    test_punc_removed = [word for word in test_punc_removed.split() if word.lower() not in stopwords.words('english')]\n",
        "    \n",
        "    return test_punc_removed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TxAYpIXXSmoZ"
      },
      "outputs": [],
      "source": [
        "# Let's test the newly added function\n",
        "reviews_df_clean = reviews_df['verified_reviews'].apply(process_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0oZBSWUVTGV9"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "# Define the cleaning pipeline we defined earlier\n",
        "vectorizer = CountVectorizer(analyzer = process_text)\n",
        "reviews_countvectorizer = vectorizer.fit_transform(reviews_df['verified_reviews'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ajna6zStUH8j",
        "outputId": "b30ffc17-3a0d-4c35-c510-03673751810b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3150, 3935)"
            ]
          },
          "metadata": {},
          "execution_count": 145
        }
      ],
      "source": [
        "reviews_countvectorizer.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HdsbGToxFCP9"
      },
      "outputs": [],
      "source": [
        "reviews = pd.DataFrame(reviews_countvectorizer.toarray())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-Y5f8HWWFglY"
      },
      "outputs": [],
      "source": [
        "X = reviews"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0TQZtuY5FnhP"
      },
      "outputs": [],
      "source": [
        "y = reviews_df['feedback']\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "We2mCIFocgtg"
      },
      "source": [
        "**MINI CHALLENGE #7:**\n",
        "- **What is the shape of X and Y**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7dofFKHGcgth",
        "outputId": "598c104b-7696-4e40-e895-612d0ed86f66"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((3150, 3935), (3150,))"
            ]
          },
          "metadata": {},
          "execution_count": 149
        }
      ],
      "source": [
        "X.shape, y.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jIVxZdZ1USAz"
      },
      "source": [
        "# TASK #9: TRAIN AND TEST NAIVE BAYES CLASSIFIER MODEL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V7M9V4QAUnOM"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "sdiBOX1xUnMo",
        "outputId": "fe332acf-a21e-4e7b-c5ad-4b7f1f45fbd3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MultinomialNB()"
            ],
            "text/html": [
              "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MultinomialNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB()</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 151
        }
      ],
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "NB_classifier = MultinomialNB()\n",
        "NB_classifier.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8CSu7xXdVyGI"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4gSgbN3JVymd"
      },
      "outputs": [],
      "source": [
        "# Predicting the Test set results\n",
        "y_predict_test = NB_classifier.predict(X_test)\n",
        "cm = confusion_matrix(y_test, y_predict_test)\n",
        "#sns.heatmap(cm, annot = True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "id": "l2sReJpmV8CK",
        "outputId": "136bd3c7-f815-4809-a6ce-c97ce7de5ded"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'              precision    recall  f1-score   support\\n\\n           0       0.64      0.38      0.47        56\\n           1       0.94      0.98      0.96       574\\n\\n    accuracy                           0.93       630\\n   macro avg       0.79      0.68      0.72       630\\nweighted avg       0.91      0.93      0.92       630\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 154
        }
      ],
      "source": [
        "classification_report(y_test, y_predict_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uIjfuDFBcgtq"
      },
      "source": [
        "**MINI CHALLENGE #8:**\n",
        "- **Train a logistic Regression classifier and assess its performance**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l7SvWr9Xcgtq"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "model = LogisticRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "cm = confusion_matrix(y_pred, y_test)\n",
        "#sns.heatmap(cm, annot = True)\n",
        "\n",
        "#print(classification_report(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "27OgYEJu9EFV"
      },
      "source": [
        "# EXCELLENT JOB! YOU SHOULD BE PROUD OF YOUR NEWLY ACQUIRED SKILLS"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ujW3rD-Xcgts"
      },
      "source": [
        "# MINI CHALLENGE SOLUTIONS"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LSj_hN6Dcgtv"
      },
      "source": [
        "**MINI CHALLENGE #2 SOLUTION:** \n",
        "- **Plot the countplot for the feedback column**\n",
        "- **Roughly how many positive and negative feedback are present in the dataset?**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hEqL2Trscgtw"
      },
      "outputs": [],
      "source": [
        "# Plot the countplot for feedback\n",
        "# Positive ~2800\n",
        "# Negative ~250\n",
        "#sns.countplot(x = reviews_df['feedback'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n-EY-L6pcgty"
      },
      "source": [
        "**MINI CHALLENGE #3 SOLUTION:**\n",
        "- **View the message with the average length**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "YOavt0ROcgty",
        "outputId": "69302fc3-f44e-4786-8898-af8fd10e354b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'work replaced expired bedside radioalarmit took realize option setting involved using touch screenmaybe said something setup process'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 157
        }
      ],
      "source": [
        "# Let's see the message with mean length \n",
        "reviews_df[reviews_df['length'] == 132]['verified_reviews'].iloc[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "upNkgZ1rcgtz"
      },
      "source": [
        "**MINI CHALLENGE #4 SOLUTION:** \n",
        "- **Plot the wordcloud of the \"negative\" dataframe** \n",
        "- **What do you notice? Does the data make sense?**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OdMi0b9Rcgt0"
      },
      "outputs": [],
      "source": [
        "sentences = negative['verified_reviews'].tolist()\n",
        "len(sentences)\n",
        "sentences_as_one_string =\" \".join(sentences)\n",
        "#plt.figure(figsize = (20,20))\n",
        "#plt.imshow(WordCloud().generate(sentences_as_one_string))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G80lM4yPcgt1"
      },
      "source": [
        "**MINI CHALLENGE #5 SOLUTION:** \n",
        "- **For the following text, create a pipeline to remove punctuations followed by removing stopwords and test the pipeline**\n",
        "- **mini_challenge = 'Here is a mini challenge, that will teach you how to remove stopwords and punctuations from text..!!'**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4PD7zjlJcguF"
      },
      "outputs": [],
      "source": [
        "mini_challenge = 'Here is a mini challenge, that will teach you how to remove stopwords and punctuations from text..!!'\n",
        "challege = [ char for char in mini_challenge  if char not in string.punctuation ]\n",
        "challenge = ''.join(challege)\n",
        "challenge = [  word for word in challenge.split() if word.lower() not in stopwords.words('english')  ] \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YkC9Nuk4cguF"
      },
      "source": [
        "**MINI CHALLENGE #6 SOLUTION:**\n",
        "- **Without doing any code, perform count vectorization for the following list:**\n",
        "    -  mini_challenge = ['Hello World','Hello Hello World','Hello World world world']\n",
        "- **Confirm your answer with code**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DxI3rZw2cguG"
      },
      "outputs": [],
      "source": [
        "mini_challenge = ['Hello World','Hello Hello World','Hello World world world']\n",
        "\n",
        "mini_challenge = ['Hello World', 'Hello Hello Hello World world', 'Hello Hello World world world World']\n",
        "\n",
        "vectorizer_challenge = CountVectorizer()\n",
        "X_challenge = vectorizer_challenge.fit_transform(mini_challenge)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HIHuMt6HcguG"
      },
      "source": [
        "**MINI CHALLENGE #7 SOLUTION:**\n",
        "- **What is the shape of X and Y**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DBXOsxjVcguG",
        "outputId": "a4124ce9-6499-44f1-fb8f-ef384e974352"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3150, 3935)"
            ]
          },
          "metadata": {},
          "execution_count": 161
        }
      ],
      "source": [
        "X.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pcqaznGHcguH",
        "outputId": "91e13e78-1b99-4428-df21-b05aa63c662b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3150,)"
            ]
          },
          "metadata": {},
          "execution_count": 162
        }
      ],
      "source": [
        "y.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kl4iEf0OcguH"
      },
      "source": [
        "**MINI CHALLENGE #8 SOLUTION:**\n",
        "- **Train a logistic Regression classifier and assess its performance**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8LumEAfocguH"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "model = LogisticRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "cm = confusion_matrix(y_pred, y_test)\n",
        "#sns.heatmap(cm, annot = True)\n",
        "\n",
        "#print(classification_report(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "86gXAsYdcguI"
      },
      "source": [
        "# Excellent Job!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c4acVO-DjBBh"
      },
      "source": [
        "# LDA PART"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9JSzP36UL3jO"
      },
      "outputs": [],
      "source": [
        "import spacy  # for our NLP processing\n",
        "import nltk  # to use the stopwords library\n",
        "import string  # for a list of all punctuation\n",
        "from nltk.corpus import stopwords  # for a list of stopwords\n",
        "import gensim\n",
        "from sklearn.manifold import TSNE\n",
        "import pathlib\n",
        "import pandas as pd\n",
        "from wordcloud import STOPWORDS\n",
        "import re\n",
        "import json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_kfhrAkZLwYz"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Now we can load and use spacy to analyse our reviews\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "\n",
        "def format_topics_sentences(ldamodel, corpus, texts, dates):\n",
        "    sent_topics_df = pd.DataFrame()\n",
        "\n",
        "    # Get main topic in each document\n",
        "    for i, row in enumerate(ldamodel[corpus]):\n",
        "        row = sorted(row, key=lambda x: (x[1]), reverse=True)\n",
        "        # Get the Dominant topic, Perc Contribution and Keywords for each document\n",
        "        for j, (topic_num, prop_topic) in enumerate(row):\n",
        "            if j == 0:  # => dominant topic\n",
        "                wp = ldamodel.show_topic(topic_num)\n",
        "                topic_keywords = \", \".join([word for word, prop in wp])\n",
        "                sent_topics_df = sent_topics_df.append(\n",
        "                    pd.Series([int(topic_num), round(prop_topic, 4), topic_keywords]),\n",
        "                    ignore_index=True,\n",
        "                )\n",
        "            else:\n",
        "                break\n",
        "    sent_topics_df.columns = [\"Dominant_Topic\", \"Perc_Contribution\", \"Topic_Keywords\"]\n",
        "\n",
        "    # Add original text to the end of the output\n",
        "    contents = pd.Series(texts)\n",
        "\n",
        "    sent_topics_df = pd.concat([sent_topics_df, contents, pd.Series(dates)], axis=1)\n",
        "    return sent_topics_df\n",
        "\n",
        "\n",
        "def lda_analysis(df, stop_words):\n",
        "    \n",
        "    def cleanup_text(doc):\n",
        "        doc = nlp(doc, disable=[\"parser\", \"ner\"])\n",
        "        tokens = [tok.lemma_.lower().strip() for tok in doc if tok.lemma_ != \"-PRON-\"]\n",
        "        tokens = [\n",
        "            tok for tok in tokens if tok not in stop_words and tok not in punctuations\n",
        "        ]\n",
        "        return tokens\n",
        "\n",
        "    # Clean up and take only rows where we have text\n",
        "    df = df[pd.notnull(df[\"verified_reviews\"])]\n",
        "    docs = list(df[\"verified_reviews\"].values)\n",
        "\n",
        "    punctuations = string.punctuation\n",
        "\n",
        "    processed_docs = list(map(cleanup_text, docs))\n",
        "    print(\"len(processed_docs)\", len(processed_docs))\n",
        "    if len(processed_docs) < 11:\n",
        "        print(\"INSUFFICIENT DOCS TO RUN LINEAR DISCRIMINANT ANALYSIS\")\n",
        "        return (None, None, None, None)\n",
        "\n",
        "    dictionary = gensim.corpora.Dictionary(processed_docs)\n",
        "    bow_corpus = [dictionary.doc2bow(doc) for doc in processed_docs]\n",
        "    print(\"len(bow_corpus)\", len(bow_corpus))\n",
        "    print(\"dictionary\", len(list(dictionary.keys())))\n",
        "    if len(list(dictionary.keys())) < 1:\n",
        "        print(\"INSUFFICIENT DICTS TO RUN LINEAR DISCRIMINANT ANALYSIS\")\n",
        "        return (None, None, None, None)\n",
        "\n",
        "    lda_model = gensim.models.LdaModel(\n",
        "        bow_corpus, num_topics=5, id2word=dictionary, passes=10\n",
        "    )\n",
        "\n",
        "    df_topic_sents_keywords = format_topics_sentences(\n",
        "        ldamodel=lda_model,\n",
        "        corpus=bow_corpus,\n",
        "        texts=docs,\n",
        "        dates=list(df[\"Date received\"].values),\n",
        "    )\n",
        "    print(\"len(df_topic_sents_keywords)\", len(df_topic_sents_keywords))\n",
        "    print(\"df_topic_sents_keywords.head()\", df_topic_sents_keywords.head())\n",
        "    df_dominant_topic = df_topic_sents_keywords.reset_index()\n",
        "    df_dominant_topic.columns = [\n",
        "        \"Document_No\",\n",
        "        \"Dominant_Topic\",\n",
        "        \"Topic_Perc_Contrib\",\n",
        "        \"Keywords\",\n",
        "        \"Text\",\n",
        "        \"Date\",\n",
        "    ]\n",
        "\n",
        "    topic_num, tsne_lda = tsne_analysis(lda_model, bow_corpus)\n",
        "\n",
        "    return (tsne_lda, lda_model, topic_num, df_dominant_topic)\n",
        "\n",
        "\n",
        "def tsne_analysis(ldamodel, corpus):\n",
        "    topic_weights = []\n",
        "    for i, row_list in enumerate(ldamodel[corpus]):\n",
        "        topic_weights.append([w for i, w in row_list])\n",
        "\n",
        "    # Array of topic weights\n",
        "    df_topics = pd.DataFrame(topic_weights).fillna(0).values\n",
        "\n",
        "\n",
        "\n",
        "    # Dominant topic number in each doc\n",
        "    topic_nums = np.argmax(df_topics, axis=1)\n",
        "\n",
        "    # tSNE Dimension Reduction\n",
        "    try:\n",
        "        tsne_model = TSNE(\n",
        "            n_components=2, verbose=1, random_state=0, angle=0.99, init=\"pca\"\n",
        "        )\n",
        "        tsne_lda = tsne_model.fit_transform(df_topics)\n",
        "    except:\n",
        "        print(\"TSNE_ANALYSIS WENT WRONG, PLEASE RE-CHECK YOUR DATASET\")\n",
        "        return (topic_nums, None)\n",
        "\n",
        "    return (topic_nums, tsne_lda)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eSHQpBATN2Wo"
      },
      "outputs": [],
      "source": [
        "GLOBAL_DF = reviews_df.copy()\n",
        "\n",
        "ADDITIONAL_STOPWORDS = [\n",
        "    \"XXXX\",\n",
        "    \"XX\",\n",
        "    \"xx\",\n",
        "    \"xxxx\",\n",
        "    \"n't\"\n",
        "]\n",
        "for stopword in ADDITIONAL_STOPWORDS:\n",
        "    STOPWORDS.add(stopword)\n",
        "\n",
        "def add_stopwords(selected_bank):\n",
        "\n",
        "    selected_bank_words = re.findall(r\"[\\w']+\", selected_bank)\n",
        "    for word in selected_bank_words:\n",
        "        STOPWORDS.add(word.lower())\n",
        "\n",
        "    #print(\"Added %s stopwords:\" % selected_bank)\n",
        "    #for word in selected_bank_words:\n",
        "        #print(\"\\t\", word)\n",
        "    return STOPWORDS\n",
        "\n",
        "def precompute_all_lda():\n",
        "    \"\"\" QD function for precomputing all necessary LDA results\n",
        "     to allow much faster load times when the app runs. \"\"\"\n",
        "\n",
        "    failed_banks = []\n",
        "    counter = 0\n",
        "    bank_names = GLOBAL_DF[\"variation\"].value_counts().keys().tolist()\n",
        "    results = {}\n",
        "\n",
        "    for bank in bank_names:\n",
        "        try:\n",
        "            print(\"crunching LDA for: \", bank)\n",
        "            add_stopwords(bank)\n",
        "            bank_df = GLOBAL_DF[GLOBAL_DF[\"variation\"] == bank]\n",
        "            tsne_lda, lda_model, topic_num, df_dominant_topic = lda_analysis(\n",
        "                bank_df, list(STOPWORDS)\n",
        "            )\n",
        "\n",
        "            topic_top3words = [\n",
        "                (i, topic)\n",
        "                for i, topics in lda_model.show_topics(formatted=False)\n",
        "                for j, (topic, wt) in enumerate(topics)\n",
        "                if j < 3\n",
        "            ]\n",
        "\n",
        "            df_top3words_stacked = pd.DataFrame(\n",
        "                topic_top3words, columns=[\"topic_id\", \"words\"]\n",
        "            )\n",
        "            df_top3words = df_top3words_stacked.groupby(\"topic_id\").agg(\", \\n\".join)\n",
        "            df_top3words.reset_index(level=0, inplace=True)\n",
        "\n",
        "            # print(len(tsne_lda))\n",
        "            # print(len(df_dominant_topic))\n",
        "            tsne_df = pd.DataFrame(\n",
        "                {\n",
        "                    \"tsne_x\": tsne_lda[:, 0],\n",
        "                    \"tsne_y\": tsne_lda[:, 1],\n",
        "                    \"topic_num\": topic_num,\n",
        "                    \"doc_num\": df_dominant_topic[\"Document_No\"],\n",
        "                }\n",
        "            )\n",
        "\n",
        "            topic_top3words = [\n",
        "                (i, topic)\n",
        "                for i, topics in lda_model.show_topics(formatted=False)\n",
        "                for j, (topic, wt) in enumerate(topics)\n",
        "                if j < 3\n",
        "            ]\n",
        "\n",
        "            df_top3words_stacked = pd.DataFrame(\n",
        "                topic_top3words, columns=[\"topic_id\", \"words\"]\n",
        "            )\n",
        "            df_top3words = df_top3words_stacked.groupby(\"topic_id\").agg(\", \\n\".join)\n",
        "            df_top3words.reset_index(level=0, inplace=True)\n",
        "\n",
        "            results[str(bank)] = {\n",
        "                \"df_top3words\": df_top3words.to_json(),\n",
        "                \"tsne_df\": tsne_df.to_json(),\n",
        "                \"df_dominant_topic\": df_dominant_topic.to_json(),\n",
        "            }\n",
        "\n",
        "            counter += 1\n",
        "        except:\n",
        "            print(\"SOMETHING WENT HORRIBLY WRONG WITH : \", bank)\n",
        "            failed_banks.append(bank)\n",
        "\n",
        "    with open(\"/content/drive/MyDrive/Dash_plotly_home/precomputed.json\", \"w+\") as res_file:\n",
        "        json.dump(results, res_file)\n",
        "\n",
        "    #print(\"DONE\")\n",
        "    #print(\"did %d variations\" % counter)\n",
        "    #print(\"failed %d:\" % len(failed_banks))\n",
        "    for fail in failed_banks:\n",
        "        print(fail)   "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LxRftqUwXRL1",
        "outputId": "c9201977-f172-42a2-ef72-30e66602d33b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "crunching LDA for:  Black  Dot\n",
            "len(processed_docs) 516\n",
            "len(bow_corpus) 516\n",
            "dictionary 808\n",
            "len(df_topic_sents_keywords) 516\n",
            "df_topic_sents_keywords.head()    Dominant_Topic  Perc_Contribution  \\\n",
            "0             1.0             0.9460   \n",
            "1             3.0             0.7324   \n",
            "2             3.0             0.9322   \n",
            "3             2.0             0.7294   \n",
            "4             0.0             0.2000   \n",
            "\n",
            "                                      Topic_Keywords  \\\n",
            "0  music, wa, ask, set, thing, play, really, alex...   \n",
            "1  easy, work, set, use, still, want, thing, play...   \n",
            "2  easy, work, set, use, still, want, thing, play...   \n",
            "3  love, great, music, device, product, work, pla...   \n",
            "4  love, great, speaker, sound, alexa, good, echo...   \n",
            "\n",
            "                                                   0          1  \n",
            "0  set play home theater system fat using weather... 2018-07-31  \n",
            "1                                     beyond awesome 2018-07-31  \n",
            "2  like responds every time wa easy set still lea... 2018-07-31  \n",
            "3                                       family loved 2018-07-31  \n",
            "4                                                    2018-07-31  \n",
            "[t-SNE] Computing 91 nearest neighbors...\n",
            "[t-SNE] Indexed 516 samples in 0.001s...\n",
            "[t-SNE] Computed neighbors for 516 samples in 0.011s...\n",
            "[t-SNE] Computed conditional probabilities for sample 516 / 516\n",
            "[t-SNE] Mean sigma: 0.012245\n",
            "[t-SNE] KL divergence after 250 iterations with early exaggeration: 42.715374\n",
            "[t-SNE] KL divergence after 1000 iterations: 0.076924\n",
            "crunching LDA for:  Charcoal Fabric \n",
            "len(processed_docs) 430\n",
            "len(bow_corpus) 430\n",
            "dictionary 706\n",
            "len(df_topic_sents_keywords) 430\n",
            "df_topic_sents_keywords.head()    Dominant_Topic  Perc_Contribution  \\\n",
            "0             0.0             0.7286   \n",
            "1             4.0             0.5939   \n",
            "2             1.0             0.6648   \n",
            "3             1.0             0.5908   \n",
            "4             3.0             0.9612   \n",
            "\n",
            "                                      Topic_Keywords  \\\n",
            "0  echo, work, great, love, well, sound, still, l...   \n",
            "1  love, use, alexa, music, echo, make, wa, reall...   \n",
            "2  play, music, use, alexa, fun, love, ask, cool,...   \n",
            "3  play, music, use, alexa, fun, love, ask, cool,...   \n",
            "4  echo, music, easy, sound, set, great, wa, alex...   \n",
            "\n",
            "                                                   0          1  \n",
            "0                                          love echo 2018-07-31  \n",
            "1                                              loved 2018-07-31  \n",
            "2  lot fun thing yr old learns dinosaur control l... 2018-07-31  \n",
            "3                                              music 2018-07-31  \n",
            "4  think one ive purchased working getting one ev... 2018-07-31  \n",
            "[t-SNE] Computing 91 nearest neighbors...\n",
            "[t-SNE] Indexed 430 samples in 0.001s...\n",
            "[t-SNE] Computed neighbors for 430 samples in 0.010s...\n",
            "[t-SNE] Computed conditional probabilities for sample 430 / 430\n",
            "[t-SNE] Mean sigma: 0.019404\n",
            "[t-SNE] KL divergence after 250 iterations with early exaggeration: 42.246605\n",
            "[t-SNE] KL divergence after 1000 iterations: 0.106476\n",
            "crunching LDA for:  Configuration: Fire TV Stick\n",
            "len(processed_docs) 350\n",
            "len(bow_corpus) 350\n",
            "dictionary 779\n",
            "len(df_topic_sents_keywords) 350\n",
            "df_topic_sents_keywords.head()    Dominant_Topic  Perc_Contribution  \\\n",
            "0             2.0             0.9571   \n",
            "1             0.0             0.9322   \n",
            "2             3.0             0.7299   \n",
            "3             2.0             0.7990   \n",
            "4             0.0             0.2000   \n",
            "\n",
            "                                      Topic_Keywords  \\\n",
            "0  use, good, love, one, long, many, ⭐, easy, ale...   \n",
            "1  love, use, wa, cable, app, watch, purchase, da...   \n",
            "2  love, work, watch, alexa, wish, great, able, f...   \n",
            "3  use, good, love, one, long, many, ⭐, easy, ale...   \n",
            "4  love, use, wa, cable, app, watch, purchase, da...   \n",
            "\n",
            "                                                   0          1  \n",
            "0  ideal amazon prime first fire tv stick purchas... 2018-07-31  \n",
            "1  love finally got one everyone home importantly... 2018-07-31  \n",
            "2                                     love firestick 2018-07-31  \n",
            "3                        dont know held getting long 2018-07-31  \n",
            "4                                                    2018-07-31  \n",
            "[t-SNE] Computing 91 nearest neighbors...\n",
            "[t-SNE] Indexed 350 samples in 0.001s...\n",
            "[t-SNE] Computed neighbors for 350 samples in 0.006s...\n",
            "[t-SNE] Computed conditional probabilities for sample 350 / 350\n",
            "[t-SNE] Mean sigma: 0.053946\n",
            "[t-SNE] KL divergence after 250 iterations with early exaggeration: 42.600639\n",
            "[t-SNE] KL divergence after 800 iterations: 0.112533\n",
            "crunching LDA for:  Black  Plus\n",
            "len(processed_docs) 270\n",
            "len(bow_corpus) 270\n",
            "dictionary 1154\n",
            "len(df_topic_sents_keywords) 270\n",
            "df_topic_sents_keywords.head()    Dominant_Topic  Perc_Contribution  \\\n",
            "0             1.0             0.9645   \n",
            "1             4.0             0.6570   \n",
            "2             1.0             0.9379   \n",
            "3             4.0             0.9452   \n",
            "4             0.0             0.7908   \n",
            "\n",
            "                                      Topic_Keywords  \\\n",
            "0  use, learn, alexa, music, echo, still, wa, far...   \n",
            "1  echo, alexa, light, wa, love, hub, sound, bulb...   \n",
            "2  use, learn, alexa, music, echo, still, wa, far...   \n",
            "3  echo, alexa, light, wa, love, hub, sound, bulb...   \n",
            "4  echo, hub, bulb, light, hue, device, great, pu...   \n",
            "\n",
            "                                                   0          1  \n",
            "0  use alexa primarily listening music checking w... 2018-07-31  \n",
            "1  plug n play set simple added battery base make... 2018-07-31  \n",
            "2  shes alexa bit dense still learning way phrase... 2018-07-30  \n",
            "3  great sound easy set purchased echo plus built... 2018-07-30  \n",
            "4                                 love new echo plus 2018-07-30  \n",
            "[t-SNE] Computing 91 nearest neighbors...\n",
            "[t-SNE] Indexed 270 samples in 0.001s...\n",
            "[t-SNE] Computed neighbors for 270 samples in 0.005s...\n",
            "[t-SNE] Computed conditional probabilities for sample 270 / 270\n",
            "[t-SNE] Mean sigma: 0.021179\n",
            "[t-SNE] KL divergence after 250 iterations with early exaggeration: 42.028282\n",
            "[t-SNE] KL divergence after 1000 iterations: 0.098631\n",
            "crunching LDA for:  Black  Show\n",
            "len(processed_docs) 265\n",
            "len(bow_corpus) 265\n",
            "dictionary 990\n",
            "len(df_topic_sents_keywords) 265\n",
            "df_topic_sents_keywords.head()    Dominant_Topic  Perc_Contribution  \\\n",
            "0             3.0             0.9169   \n",
            "1             4.0             0.9369   \n",
            "2             2.0             0.9768   \n",
            "3             0.0             0.9089   \n",
            "4             4.0             0.5944   \n",
            "\n",
            "                                      Topic_Keywords  \\\n",
            "0  love, echo, great, work, well, sound, video, u...   \n",
            "1  work, good, echo, see, great, wa, ha, alexa, l...   \n",
            "2  work, echo, video, device, still, well, great,...   \n",
            "3  love, great, use, product, buy, one, enjoy, th...   \n",
            "4  work, good, echo, see, great, wa, ha, alexa, l...   \n",
            "\n",
            "                                                   0          1  \n",
            "0  love love love love feel like talking computer... 2018-07-31  \n",
            "1  love echo show able see lyric song play able p... 2018-07-31  \n",
            "2  seems work well unfortunately lot functionalit... 2018-07-31  \n",
            "3  love listening music still trying learn everyt... 2018-07-31  \n",
            "4                                               good 2018-07-31  \n",
            "[t-SNE] Computing 91 nearest neighbors...\n",
            "[t-SNE] Indexed 265 samples in 0.001s...\n",
            "[t-SNE] Computed neighbors for 265 samples in 0.005s...\n",
            "[t-SNE] Computed conditional probabilities for sample 265 / 265\n",
            "[t-SNE] Mean sigma: 0.014959\n",
            "[t-SNE] KL divergence after 250 iterations with early exaggeration: 42.780861\n",
            "[t-SNE] KL divergence after 1000 iterations: 0.066630\n",
            "crunching LDA for:  Black\n",
            "len(processed_docs) 261\n",
            "len(bow_corpus) 261\n",
            "dictionary 859\n",
            "len(df_topic_sents_keywords) 261\n",
            "df_topic_sents_keywords.head()    Dominant_Topic  Perc_Contribution  \\\n",
            "0             3.0             0.9262   \n",
            "1             4.0             0.5696   \n",
            "2             1.0             0.8651   \n",
            "3             1.0             0.8650   \n",
            "4             2.0             0.7251   \n",
            "\n",
            "                                      Topic_Keywords  \\\n",
            "0  work, great, product, time, good, sound, room,...   \n",
            "1  echo, sound, well, buy, refurbish, work, use, ...   \n",
            "2  love, new, work, one, great, refurbish, wa, al...   \n",
            "3  love, new, work, one, great, refurbish, wa, al...   \n",
            "4  buy, one, work, love, great, want, thing, wa, ...   \n",
            "\n",
            "                                                   0          1  \n",
            "0  item longer work month use connect wifi unresp... 2018-07-31  \n",
            "1  love echo dot easy fun get drop grandaughter l... 2018-07-30  \n",
            "2                       work great different new one 2018-07-30  \n",
            "3                  one going kitchen timermusic duty 2018-07-30  \n",
            "4                                          work fine 2018-07-30  \n",
            "[t-SNE] Computing 91 nearest neighbors...\n",
            "[t-SNE] Indexed 261 samples in 0.001s...\n",
            "[t-SNE] Computed neighbors for 261 samples in 0.006s...\n",
            "[t-SNE] Computed conditional probabilities for sample 261 / 261\n",
            "[t-SNE] Mean sigma: 0.052445\n",
            "[t-SNE] KL divergence after 250 iterations with early exaggeration: 41.102249\n",
            "[t-SNE] KL divergence after 1000 iterations: 0.110597\n",
            "crunching LDA for:  Black  Spot\n",
            "len(processed_docs) 241\n",
            "len(bow_corpus) 241\n",
            "dictionary 1109\n",
            "len(df_topic_sents_keywords) 241\n",
            "df_topic_sents_keywords.head()    Dominant_Topic  Perc_Contribution  \\\n",
            "0             1.0             0.8981   \n",
            "1             4.0             0.7979   \n",
            "2             2.0             0.9189   \n",
            "3             4.0             0.9361   \n",
            "4             4.0             0.7332   \n",
            "\n",
            "                                      Topic_Keywords  \\\n",
            "0  clock, great, use, love, alarm, alexa, music, ...   \n",
            "1  love, great, good, wa, use, alexa, screen, one...   \n",
            "2  love, one, wa, day, video, prime, echo, buy, c...   \n",
            "3  love, great, good, wa, use, alexa, screen, one...   \n",
            "4  love, great, good, wa, use, alexa, screen, one...   \n",
            "\n",
            "                                                   0          1  \n",
            "0        used product phone look weather watch video 2018-07-31  \n",
            "1                                amazing far got day 2018-07-30  \n",
            "2  like smaller ha never understood command easil... 2018-07-30  \n",
            "3  worthy successor echo dot right home bed room ... 2018-07-30  \n",
            "4  love device functionality amazon echo added be... 2018-07-30  \n",
            "[t-SNE] Computing 91 nearest neighbors...\n",
            "[t-SNE] Indexed 241 samples in 0.001s...\n",
            "[t-SNE] Computed neighbors for 241 samples in 0.007s...\n",
            "[t-SNE] Computed conditional probabilities for sample 241 / 241\n",
            "[t-SNE] Mean sigma: 0.013291\n",
            "[t-SNE] KL divergence after 250 iterations with early exaggeration: 39.935181\n",
            "[t-SNE] KL divergence after 1000 iterations: 0.082101\n",
            "crunching LDA for:  White  Dot\n",
            "len(processed_docs) 184\n",
            "len(bow_corpus) 184\n",
            "dictionary 377\n",
            "len(df_topic_sents_keywords) 184\n",
            "df_topic_sents_keywords.head()    Dominant_Topic  Perc_Contribution  \\\n",
            "0             3.0             0.9104   \n",
            "1             0.0             0.7325   \n",
            "2             0.0             0.5973   \n",
            "3             3.0             0.7305   \n",
            "4             4.0             0.7308   \n",
            "\n",
            "                                      Topic_Keywords  \\\n",
            "0  echo, music, love, work, easy, play, set, one,...   \n",
            "1  love, alexa, use, speaker, great, echo, house,...   \n",
            "2  love, alexa, use, speaker, great, echo, house,...   \n",
            "3  echo, music, love, work, easy, play, set, one,...   \n",
            "4  good, one, ha, speaker, still, music, need, th...   \n",
            "\n",
            "                                                   0          1  \n",
            "0  small device kid like ask question handy frien... 2018-07-31  \n",
            "1                                       love helpful 2018-07-30  \n",
            "2                                               love 2018-07-30  \n",
            "3                                      work like one 2018-07-30  \n",
            "4                                       nice product 2018-07-30  \n",
            "[t-SNE] Computing 91 nearest neighbors...\n",
            "[t-SNE] Indexed 184 samples in 0.001s...\n",
            "[t-SNE] Computed neighbors for 184 samples in 0.004s...\n",
            "[t-SNE] Computed conditional probabilities for sample 184 / 184\n",
            "[t-SNE] Mean sigma: 0.070217\n",
            "[t-SNE] KL divergence after 250 iterations with early exaggeration: 39.709888\n",
            "[t-SNE] KL divergence after 850 iterations: 0.056577\n",
            "crunching LDA for:  Heather Gray Fabric \n",
            "len(processed_docs) 157\n",
            "len(bow_corpus) 157\n",
            "dictionary 371\n",
            "len(df_topic_sents_keywords) 157\n",
            "df_topic_sents_keywords.head()    Dominant_Topic  Perc_Contribution  \\\n",
            "0             4.0             0.9526   \n",
            "1             0.0             0.7319   \n",
            "2             3.0             0.9328   \n",
            "3             2.0             0.4799   \n",
            "4             3.0             0.8987   \n",
            "\n",
            "                                      Topic_Keywords  \\\n",
            "0  sound, love, music, echo, well, speaker, play,...   \n",
            "1  great, alexa, use, music, play, speaker, thing...   \n",
            "2  love, easy, great, set, happy, wa, connect, se...   \n",
            "3  love, alexa, wife, set, app, work, echo, sound...   \n",
            "4  love, easy, great, set, happy, wa, connect, se...   \n",
            "\n",
            "                                                   0          1  \n",
            "0  received echo gift needed another bluetooth so... 2018-07-31  \n",
            "1                                         look great 2018-07-30  \n",
            "2  love i’ve listened song haven’t heard since ch... 2018-07-30  \n",
            "3                                     love wife hate 2018-07-30  \n",
            "4       really happy purchase great speaker easy set 2018-07-30  \n",
            "[t-SNE] Computing 91 nearest neighbors...\n",
            "[t-SNE] Indexed 157 samples in 0.001s...\n",
            "[t-SNE] Computed neighbors for 157 samples in 0.072s...\n",
            "[t-SNE] Computed conditional probabilities for sample 157 / 157\n",
            "[t-SNE] Mean sigma: 0.058434\n",
            "[t-SNE] KL divergence after 250 iterations with early exaggeration: 40.249809\n",
            "[t-SNE] KL divergence after 1000 iterations: 0.059095\n",
            "crunching LDA for:  White  Spot\n",
            "len(processed_docs) 109\n",
            "len(bow_corpus) 109\n",
            "dictionary 748\n",
            "len(df_topic_sents_keywords) 109\n",
            "df_topic_sents_keywords.head()    Dominant_Topic  Perc_Contribution  \\\n",
            "0             0.0             0.9597   \n",
            "1             1.0             0.9848   \n",
            "2             1.0             0.9494   \n",
            "3             3.0             0.8835   \n",
            "4             3.0             0.8836   \n",
            "\n",
            "                                      Topic_Keywords  \\\n",
            "0  use, clock, love, product, lot, set, item, pri...   \n",
            "1  echo, one, use, love, device, alarm, music, se...   \n",
            "2  echo, one, use, love, device, alarm, music, se...   \n",
            "3  love, screen, alexa, echo, use, great, clock, ...   \n",
            "4  love, screen, alexa, echo, use, great, clock, ...   \n",
            "\n",
            "                                                   0          1  \n",
            "0  don’t use much thought would synced kasacam us... 2018-07-31  \n",
            "1  love echo spot bedside alarm clock size device... 2018-07-30  \n",
            "2  thing like echo spot voice command feature ask... 2018-07-30  \n",
            "3     love perfect alarm clock replacement plus much 2018-07-30  \n",
            "4  absolutely love product wish would bought inst... 2018-07-30  \n",
            "[t-SNE] Computing 91 nearest neighbors...\n",
            "[t-SNE] Indexed 109 samples in 0.000s...\n",
            "[t-SNE] Computed neighbors for 109 samples in 0.003s...\n",
            "[t-SNE] Computed conditional probabilities for sample 109 / 109\n",
            "[t-SNE] Mean sigma: 0.029397\n",
            "[t-SNE] KL divergence after 250 iterations with early exaggeration: 48.232788\n",
            "[t-SNE] KL divergence after 850 iterations: 0.041004\n",
            "crunching LDA for:  White\n",
            "len(processed_docs) 91\n",
            "len(bow_corpus) 91\n",
            "dictionary 425\n",
            "len(df_topic_sents_keywords) 91\n",
            "df_topic_sents_keywords.head()    Dominant_Topic  Perc_Contribution  \\\n",
            "0             4.0             0.9676   \n",
            "1             4.0             0.7276   \n",
            "2             2.0             0.9375   \n",
            "3             1.0             0.9462   \n",
            "4             1.0             0.8656   \n",
            "\n",
            "                                      Topic_Keywords  \\\n",
            "0  love, echo, use, one, good, perfect, great, we...   \n",
            "1  love, echo, use, one, good, perfect, great, we...   \n",
            "2  new, one, work, echo, refurbish, buy, alexa, s...   \n",
            "3  talk, love, buy, new, perfect, good, refurb, o...   \n",
            "4  talk, love, buy, new, perfect, good, refurb, o...   \n",
            "\n",
            "                                                   0          1  \n",
            "0  love volume could definitely use boost better ... 2018-07-30  \n",
            "1                                           one love 2018-07-29  \n",
            "2  sure feel echo dot many thing need get used as... 2018-07-29  \n",
            "3  small echo dot amazing sound come greatit chan... 2018-07-28  \n",
            "4               talk time song aren’t dislike device 2018-07-28  \n",
            "[t-SNE] Computing 90 nearest neighbors...\n",
            "[t-SNE] Indexed 91 samples in 0.000s...\n",
            "[t-SNE] Computed neighbors for 91 samples in 0.006s...\n",
            "[t-SNE] Computed conditional probabilities for sample 91 / 91\n",
            "[t-SNE] Mean sigma: 0.311614\n",
            "[t-SNE] KL divergence after 250 iterations with early exaggeration: 50.108059\n",
            "[t-SNE] KL divergence after 950 iterations: 0.039991\n",
            "crunching LDA for:  Sandstone Fabric \n",
            "len(processed_docs) 90\n",
            "len(bow_corpus) 90\n",
            "dictionary 292\n",
            "len(df_topic_sents_keywords) 90\n",
            "df_topic_sents_keywords.head()    Dominant_Topic  Perc_Contribution  \\\n",
            "0             1.0             0.9763   \n",
            "1             0.0             0.9777   \n",
            "2             1.0             0.9464   \n",
            "3             3.0             0.7333   \n",
            "4             0.0             0.9109   \n",
            "\n",
            "                                      Topic_Keywords  \\\n",
            "0  work, wa, echo, sound, music, learn, use, bedr...   \n",
            "1  still, great, sound, use, pretty, thing, alexa...   \n",
            "2  work, wa, echo, sound, music, learn, use, bedr...   \n",
            "3  love, alexa, great, echo, set, respond, well, ...   \n",
            "4  still, great, sound, use, pretty, thing, alexa...   \n",
            "\n",
            "                                                   0          1  \n",
            "0  without cellphone cannot use many feature ipad... 2018-07-31  \n",
            "1  liked original echo shorter greater fabriccolo... 2018-07-30  \n",
            "2  got second unit bedroom wa expecting sound imp... 2018-07-30  \n",
            "3                                    amazing product 2018-07-30  \n",
            "4  still learning capabilitiesbut far pretty pret... 2018-07-30  \n",
            "[t-SNE] Computing 89 nearest neighbors...\n",
            "[t-SNE] Indexed 90 samples in 0.000s...\n",
            "[t-SNE] Computed neighbors for 90 samples in 0.003s...\n",
            "[t-SNE] Computed conditional probabilities for sample 90 / 90\n",
            "[t-SNE] Mean sigma: 0.544361\n",
            "[t-SNE] KL divergence after 250 iterations with early exaggeration: 48.112350\n",
            "[t-SNE] KL divergence after 700 iterations: 0.047943\n",
            "crunching LDA for:  White  Show\n",
            "len(processed_docs) 85\n",
            "len(bow_corpus) 85\n",
            "dictionary 507\n",
            "len(df_topic_sents_keywords) 85\n",
            "df_topic_sents_keywords.head()    Dominant_Topic  Perc_Contribution  \\\n",
            "0             0.0             0.7333   \n",
            "1             0.0             0.5999   \n",
            "2             4.0             0.9192   \n",
            "3             2.0             0.9379   \n",
            "4             0.0             0.2000   \n",
            "\n",
            "                                      Topic_Keywords  \\\n",
            "0  echo, alexa, love, home, far, cook, expect, fi...   \n",
            "1  echo, alexa, love, home, far, cook, expect, fi...   \n",
            "2  alexa, easy, use, learn, love, echo, everythin...   \n",
            "3  sound, echo, use, love, great, well, much, wor...   \n",
            "4  echo, alexa, love, home, far, cook, expect, fi...   \n",
            "\n",
            "                                                   0          1  \n",
            "0                               pleasedsimple figure 2018-07-31  \n",
            "1                               expectedalready show 2018-07-31  \n",
            "2  excellent listen music audio book look camera ... 2018-07-31  \n",
            "3  like echo show best big screen watch movie pre... 2018-07-30  \n",
            "4                                                    2018-07-30  \n",
            "[t-SNE] Computing 84 nearest neighbors...\n",
            "[t-SNE] Indexed 85 samples in 0.000s...\n",
            "[t-SNE] Computed neighbors for 85 samples in 0.003s...\n",
            "[t-SNE] Computed conditional probabilities for sample 85 / 85\n",
            "[t-SNE] Mean sigma: 0.555901\n",
            "[t-SNE] KL divergence after 250 iterations with early exaggeration: 47.004753\n",
            "[t-SNE] KL divergence after 1000 iterations: 0.062104\n",
            "crunching LDA for:  White  Plus\n",
            "len(processed_docs) 78\n",
            "len(bow_corpus) 78\n",
            "dictionary 598\n",
            "len(df_topic_sents_keywords) 78\n",
            "df_topic_sents_keywords.head()    Dominant_Topic  Perc_Contribution  \\\n",
            "0             2.0             0.9423   \n",
            "1             1.0             0.9092   \n",
            "2             0.0             0.8381   \n",
            "3             1.0             0.9590   \n",
            "4             0.0             0.8975   \n",
            "\n",
            "                                      Topic_Keywords  \\\n",
            "0  love, great, work, hub, music, answer, questio...   \n",
            "1  echo, work, alexa, device, buy, hub, ha, love,...   \n",
            "2  light, echo, love, sound, buy, use, amazon, tu...   \n",
            "3  echo, work, alexa, device, buy, hub, ha, love,...   \n",
            "4  light, echo, love, sound, buy, use, amazon, tu...   \n",
            "\n",
            "                                                   0          1  \n",
            "0  great speaker n love much alexa tap it’s defin... 2018-07-30  \n",
            "1  like built hub plus unit sound great wish volu... 2018-07-30  \n",
            "2                       happy echo plus fun learning 2018-07-30  \n",
            "3  around week love control item house even i’m m... 2018-07-30  \n",
            "4   know needed plugged work far experience positive 2018-07-30  \n",
            "[t-SNE] Computing 77 nearest neighbors...\n",
            "[t-SNE] Indexed 78 samples in 0.000s...\n",
            "[t-SNE] Computed neighbors for 78 samples in 0.010s...\n",
            "[t-SNE] Computed conditional probabilities for sample 78 / 78\n",
            "[t-SNE] Mean sigma: 0.597759\n",
            "[t-SNE] KL divergence after 250 iterations with early exaggeration: 51.022980\n",
            "[t-SNE] KL divergence after 800 iterations: 0.051555\n",
            "crunching LDA for:  Oak Finish \n",
            "len(processed_docs) 14\n",
            "len(bow_corpus) 14\n",
            "dictionary 50\n",
            "len(df_topic_sents_keywords) 14\n",
            "df_topic_sents_keywords.head()    Dominant_Topic  Perc_Contribution  \\\n",
            "0             0.0             0.9619   \n",
            "1             0.0             0.5999   \n",
            "2             3.0             0.8396   \n",
            "3             1.0             0.9724   \n",
            "4             1.0             0.7332   \n",
            "\n",
            "                                      Topic_Keywords  \\\n",
            "0  expect, come, thing, little, purchase, time, e...   \n",
            "1  expect, come, thing, little, purchase, time, e...   \n",
            "2  love, buy, alexa, friend, entertainment, expec...   \n",
            "3  play, great, music, connection, product, versa...   \n",
            "4  play, great, music, connection, product, versa...   \n",
            "\n",
            "                                                   0          1  \n",
            "0  purchased mother knee problem give something t... 2018-07-30  \n",
            "1                                           expected 2018-07-30  \n",
            "2                    love alexa bought others friend 2018-07-30  \n",
            "3  star generally like product great ask like pla... 2018-07-30  \n",
            "4                                      versatile fun 2018-07-30  \n",
            "TSNE_ANALYSIS WENT WRONG, PLEASE RE-CHECK YOUR DATASET\n",
            "SOMETHING WENT HORRIBLY WRONG WITH :  Oak Finish \n",
            "crunching LDA for:  Walnut Finish \n",
            "len(processed_docs) 9\n",
            "INSUFFICIENT DOCS TO RUN LINEAR DISCRIMINANT ANALYSIS\n",
            "SOMETHING WENT HORRIBLY WRONG WITH :  Walnut Finish \n",
            "Oak Finish \n",
            "Walnut Finish \n"
          ]
        }
      ],
      "source": [
        "precompute_all_lda()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5fkbGLi7IXtx"
      },
      "source": [
        "# EMBEDDING VECTORS PART"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FK2of9aCIc5J"
      },
      "outputs": [],
      "source": [
        "vects_df = embed_df.copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z4-oKraqLju1"
      },
      "outputs": [],
      "source": [
        "#words converted to sentences by tfidf weights.\n",
        "#Step 1. Prepare data\n",
        "#step 2. Have bogus word2vec (of the size of our vocab)\n",
        "#Step 3. Calculate a column containing word2vec for sentences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ycngR8FjlHKq"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "tfidf = TfidfVectorizer()\n",
        "tfidf_matrix = tfidf.fit_transform(vects_df.bigram).todense()\n",
        "vocab = tfidf.vocabulary_\n",
        "#vocab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xyT7EVUNlZnx"
      },
      "outputs": [],
      "source": [
        "word2vec = np.random.randn(len(vocab),300)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4EFsPpfulc9x"
      },
      "outputs": [],
      "source": [
        "sent2vec_matrix = np.dot(tfidf_matrix, word2vec) # word2vec here contains vectors in the same order as in vocab\n",
        "vects_df[\"ngram2vec\"] = sent2vec_matrix.tolist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rmgivp_ylqyI"
      },
      "outputs": [],
      "source": [
        "#vects_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fi5Lq-URVtfx"
      },
      "outputs": [],
      "source": [
        "vects_df = vects_df.ngram2vec.apply(pd.Series) #split horizontally "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "id": "0QPUX9Iz6jGp",
        "outputId": "b2a86f44-bc05-48ac-8e9b-1b2027700726"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nvects_df.to_csv(\\'/content/drive/MyDrive/Dash_plotly_home/vects_df_n.csv\\',index = False)\\nfiles.download(\\'/content/drive/MyDrive/Dash_plotly_home/vects_df_n.csv\\')\\n!cp -r \"/content/drive/MyDrive/Dash_plotly_home/vects_df_n.csv\" \"/content/drive/MyDrive/Dash_plotly_home/\"\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 175
        }
      ],
      "source": [
        "from google.colab import files\n",
        "\"\"\"\n",
        "vects_df.to_csv('/content/drive/MyDrive/Dash_plotly_home/vects_df_n.csv',index = False)\n",
        "files.download('/content/drive/MyDrive/Dash_plotly_home/vects_df_n.csv')\n",
        "!cp -r \"/content/drive/MyDrive/Dash_plotly_home/vects_df_n.csv\" \"/content/drive/MyDrive/Dash_plotly_home/\"\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1sklXMphtdgN"
      },
      "source": [
        "# DASH PART"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DUTV_1jZk9Jl"
      },
      "outputs": [],
      "source": [
        "import locale\n",
        "def getpreferredencoding(do_setlocale = True):\n",
        "    return \"UTF-8\"\n",
        "locale.getpreferredencoding = getpreferredencoding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t32BPqh8n29w",
        "outputId": "264f3596-98f9-413e-f586-f6d2cf12afc3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: dash in /usr/local/lib/python3.8/dist-packages (2.8.1)\n",
            "Requirement already satisfied: pip in /usr/local/lib/python3.8/dist-packages (22.0.4)\n",
            "Requirement already satisfied: install in /usr/local/lib/python3.8/dist-packages (1.3.5)\n",
            "Requirement already satisfied: emoji in /usr/local/lib/python3.8/dist-packages (2.2.0)\n",
            "Requirement already satisfied: dash-table==5.0.0 in /usr/local/lib/python3.8/dist-packages (from dash) (5.0.0)\n",
            "Requirement already satisfied: dash-html-components==2.0.0 in /usr/local/lib/python3.8/dist-packages (from dash) (2.0.0)\n",
            "Requirement already satisfied: dash-core-components==2.0.0 in /usr/local/lib/python3.8/dist-packages (from dash) (2.0.0)\n",
            "Requirement already satisfied: Flask>=1.0.4 in /usr/local/lib/python3.8/dist-packages (from dash) (2.2.3)\n",
            "Requirement already satisfied: plotly>=5.0.0 in /usr/local/lib/python3.8/dist-packages (from dash) (5.5.0)\n",
            "Requirement already satisfied: importlib-metadata>=3.6.0 in /usr/local/lib/python3.8/dist-packages (from Flask>=1.0.4->dash) (6.0.0)\n",
            "Requirement already satisfied: itsdangerous>=2.0 in /usr/local/lib/python3.8/dist-packages (from Flask>=1.0.4->dash) (2.1.2)\n",
            "Requirement already satisfied: Werkzeug>=2.2.2 in /usr/local/lib/python3.8/dist-packages (from Flask>=1.0.4->dash) (2.2.3)\n",
            "Requirement already satisfied: Jinja2>=3.0 in /usr/local/lib/python3.8/dist-packages (from Flask>=1.0.4->dash) (3.1.2)\n",
            "Requirement already satisfied: click>=8.0 in /usr/local/lib/python3.8/dist-packages (from Flask>=1.0.4->dash) (8.1.3)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.8/dist-packages (from plotly>=5.0.0->dash) (8.2.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from plotly>=5.0.0->dash) (1.15.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata>=3.6.0->Flask>=1.0.4->dash) (3.15.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.8/dist-packages (from Jinja2>=3.0->Flask>=1.0.4->dash) (2.1.2)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: dash_bootstrap_components in /usr/local/lib/python3.8/dist-packages (1.4.0)\n",
            "Requirement already satisfied: dash>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from dash_bootstrap_components) (2.8.1)\n",
            "Requirement already satisfied: dash-core-components==2.0.0 in /usr/local/lib/python3.8/dist-packages (from dash>=2.0.0->dash_bootstrap_components) (2.0.0)\n",
            "Requirement already satisfied: dash-html-components==2.0.0 in /usr/local/lib/python3.8/dist-packages (from dash>=2.0.0->dash_bootstrap_components) (2.0.0)\n",
            "Requirement already satisfied: Flask>=1.0.4 in /usr/local/lib/python3.8/dist-packages (from dash>=2.0.0->dash_bootstrap_components) (2.2.3)\n",
            "Requirement already satisfied: plotly>=5.0.0 in /usr/local/lib/python3.8/dist-packages (from dash>=2.0.0->dash_bootstrap_components) (5.5.0)\n",
            "Requirement already satisfied: dash-table==5.0.0 in /usr/local/lib/python3.8/dist-packages (from dash>=2.0.0->dash_bootstrap_components) (5.0.0)\n",
            "Requirement already satisfied: Werkzeug>=2.2.2 in /usr/local/lib/python3.8/dist-packages (from Flask>=1.0.4->dash>=2.0.0->dash_bootstrap_components) (2.2.3)\n",
            "Requirement already satisfied: Jinja2>=3.0 in /usr/local/lib/python3.8/dist-packages (from Flask>=1.0.4->dash>=2.0.0->dash_bootstrap_components) (3.1.2)\n",
            "Requirement already satisfied: importlib-metadata>=3.6.0 in /usr/local/lib/python3.8/dist-packages (from Flask>=1.0.4->dash>=2.0.0->dash_bootstrap_components) (6.0.0)\n",
            "Requirement already satisfied: click>=8.0 in /usr/local/lib/python3.8/dist-packages (from Flask>=1.0.4->dash>=2.0.0->dash_bootstrap_components) (8.1.3)\n",
            "Requirement already satisfied: itsdangerous>=2.0 in /usr/local/lib/python3.8/dist-packages (from Flask>=1.0.4->dash>=2.0.0->dash_bootstrap_components) (2.1.2)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.8/dist-packages (from plotly>=5.0.0->dash>=2.0.0->dash_bootstrap_components) (8.2.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from plotly>=5.0.0->dash>=2.0.0->dash_bootstrap_components) (1.15.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata>=3.6.0->Flask>=1.0.4->dash>=2.0.0->dash_bootstrap_components) (3.15.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.8/dist-packages (from Jinja2>=3.0->Flask>=1.0.4->dash>=2.0.0->dash_bootstrap_components) (2.1.2)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: jupyter-dash in /usr/local/lib/python3.8/dist-packages (0.4.2)\n",
            "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.8/dist-packages (from jupyter-dash) (1.5.6)\n",
            "Requirement already satisfied: ipykernel in /usr/local/lib/python3.8/dist-packages (from jupyter-dash) (5.3.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from jupyter-dash) (2.25.1)\n",
            "Requirement already satisfied: ansi2html in /usr/local/lib/python3.8/dist-packages (from jupyter-dash) (1.8.0)\n",
            "Requirement already satisfied: dash in /usr/local/lib/python3.8/dist-packages (from jupyter-dash) (2.8.1)\n",
            "Requirement already satisfied: retrying in /usr/local/lib/python3.8/dist-packages (from jupyter-dash) (1.3.4)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.8/dist-packages (from jupyter-dash) (7.9.0)\n",
            "Requirement already satisfied: flask in /usr/local/lib/python3.8/dist-packages (from jupyter-dash) (2.2.3)\n",
            "Requirement already satisfied: dash-table==5.0.0 in /usr/local/lib/python3.8/dist-packages (from dash->jupyter-dash) (5.0.0)\n",
            "Requirement already satisfied: plotly>=5.0.0 in /usr/local/lib/python3.8/dist-packages (from dash->jupyter-dash) (5.5.0)\n",
            "Requirement already satisfied: dash-html-components==2.0.0 in /usr/local/lib/python3.8/dist-packages (from dash->jupyter-dash) (2.0.0)\n",
            "Requirement already satisfied: dash-core-components==2.0.0 in /usr/local/lib/python3.8/dist-packages (from dash->jupyter-dash) (2.0.0)\n",
            "Requirement already satisfied: click>=8.0 in /usr/local/lib/python3.8/dist-packages (from flask->jupyter-dash) (8.1.3)\n",
            "Requirement already satisfied: itsdangerous>=2.0 in /usr/local/lib/python3.8/dist-packages (from flask->jupyter-dash) (2.1.2)\n",
            "Requirement already satisfied: Jinja2>=3.0 in /usr/local/lib/python3.8/dist-packages (from flask->jupyter-dash) (3.1.2)\n",
            "Requirement already satisfied: importlib-metadata>=3.6.0 in /usr/local/lib/python3.8/dist-packages (from flask->jupyter-dash) (6.0.0)\n",
            "Requirement already satisfied: Werkzeug>=2.2.2 in /usr/local/lib/python3.8/dist-packages (from flask->jupyter-dash) (2.2.3)\n",
            "Requirement already satisfied: tornado>=4.2 in /usr/local/lib/python3.8/dist-packages (from ipykernel->jupyter-dash) (6.2)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.8/dist-packages (from ipykernel->jupyter-dash) (6.1.12)\n",
            "Requirement already satisfied: traitlets>=4.1.0 in /usr/local/lib/python3.8/dist-packages (from ipykernel->jupyter-dash) (5.7.1)\n",
            "Requirement already satisfied: jedi>=0.10 in /usr/local/lib/python3.8/dist-packages (from ipython->jupyter-dash) (0.18.2)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.8/dist-packages (from ipython->jupyter-dash) (4.8.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.8/dist-packages (from ipython->jupyter-dash) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.8/dist-packages (from ipython->jupyter-dash) (0.7.5)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.8/dist-packages (from ipython->jupyter-dash) (2.6.1)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.8/dist-packages (from ipython->jupyter-dash) (57.4.0)\n",
            "Requirement already satisfied: prompt-toolkit<2.1.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from ipython->jupyter-dash) (2.0.10)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.8/dist-packages (from ipython->jupyter-dash) (0.2.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->jupyter-dash) (2.10)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->jupyter-dash) (4.0.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->jupyter-dash) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->jupyter-dash) (1.26.14)\n",
            "Requirement already satisfied: six>=1.7.0 in /usr/local/lib/python3.8/dist-packages (from retrying->jupyter-dash) (1.15.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata>=3.6.0->flask->jupyter-dash) (3.15.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.8/dist-packages (from jedi>=0.10->ipython->jupyter-dash) (0.8.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.8/dist-packages (from Jinja2>=3.0->flask->jupyter-dash) (2.1.2)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.8/dist-packages (from plotly>=5.0.0->dash->jupyter-dash) (8.2.2)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.8/dist-packages (from prompt-toolkit<2.1.0,>=2.0.0->ipython->jupyter-dash) (0.2.6)\n",
            "Requirement already satisfied: jupyter-core>=4.6.0 in /usr/local/lib/python3.8/dist-packages (from jupyter-client->ipykernel->jupyter-dash) (5.2.0)\n",
            "Requirement already satisfied: pyzmq>=13 in /usr/local/lib/python3.8/dist-packages (from jupyter-client->ipykernel->jupyter-dash) (23.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.8/dist-packages (from jupyter-client->ipykernel->jupyter-dash) (2.8.2)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.8/dist-packages (from pexpect->ipython->jupyter-dash) (0.7.0)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.8/dist-packages (from jupyter-core>=4.6.0->jupyter-client->ipykernel->jupyter-dash) (3.0.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install dash pip install emoji\n",
        "!pip install dash_bootstrap_components\n",
        "!pip install jupyter-dash"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "lX_lml8RtmTW",
        "outputId": "12d29ed8-34f9-46a5-fa17-180c8d9ba554"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "        <script type=\"text/javascript\">\n",
              "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
              "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
              "        if (typeof require !== 'undefined') {\n",
              "        require.undef(\"plotly\");\n",
              "        requirejs.config({\n",
              "            paths: {\n",
              "                'plotly': ['https://cdn.plot.ly/plotly-2.8.3.min']\n",
              "            }\n",
              "        });\n",
              "        require(['plotly'], function(Plotly) {\n",
              "            window._Plotly = Plotly;\n",
              "        });\n",
              "        }\n",
              "        </script>\n",
              "        "
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "#since we are using google colab/jupyter we should use JupyterDash\n",
        "import dash_bootstrap_components as dbc\n",
        "from jupyter_dash import JupyterDash\n",
        "import dash\n",
        "from dash.dependencies import Input, Output\n",
        "import dash_table\n",
        "import dash_core_components as dcc\n",
        "import dash_html_components as html\n",
        "import pandas as pd\n",
        "import numpy as np \n",
        "import plotly.graph_objs as go\n",
        "import emoji\n",
        "import pandas as pd\n",
        "import plotly\n",
        "from plotly.offline import iplot\n",
        "from plotly.offline import init_notebook_mode, iplot\n",
        "from plotly.offline import init_notebook_mode,iplot\n",
        "import plotly.graph_objects as go\n",
        "import cufflinks as cf\n",
        "init_notebook_mode(connected=True)\n",
        "import plotly.express as px\n",
        "from dash.dependencies import Output, Input, State\n",
        "from dateutil import relativedelta\n",
        "from wordcloud import WordCloud, STOPWORDS\n",
        "from sklearn.manifold import TSNE\n",
        "import pathlib\n",
        "import json\n",
        "import pathlib\n",
        "import re\n",
        "import json\n",
        "from datetime import datetime\n",
        "import flask"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QoM1kVOauF-D"
      },
      "outputs": [],
      "source": [
        "#app = dash.Dash(__name__)   #,server= server , routes_pathname_prefix='/dash/' \n",
        "app = JupyterDash(__name__)  #since we are using google colab/jupyter we should use JupyterDash\n",
        " \n",
        "#app = dash.Dash(__name__, external_stylesheets=[dbc.themes.BOOTSTRAP])\n",
        "#server = app.server  # for Heroku deployment"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install dash_table_experiments"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Xv_c5_xJu9u",
        "outputId": "6661f9cc-0aa0-495e-b489-2f18dd2fefcb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: dash_table_experiments in /usr/local/lib/python3.8/dist-packages (0.6.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vWQwwYY3o3Dd"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "import dash_table_experiments as dte"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YfU5mPgRoEMc"
      },
      "outputs": [],
      "source": [
        "\n",
        "    \n",
        "file = open(\"/content/drive/MyDrive/Dash_plotly_home/trained_model.pkl\", 'rb') \n",
        "pickle_model = pickle.load(file)\n",
        "\n",
        "file = open(\"/content/drive/MyDrive/Dash_plotly_home/vocab.pkl\", 'rb') \n",
        "vocab = pickle.load(file)\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XG7RHTWILAvW"
      },
      "outputs": [],
      "source": [
        "DATA_PATH = \"/content/drive/MyDrive/Dash_plotly_home\"\n",
        "#EXTERNAL_STYLESHEETS = [\"https://codepen.io/chriddyp/pen/bWLwgP.css\"]\n",
        "FILENAME_PRECOMPUTED = \"/precomputed.json\"\n",
        "\n",
        "#PLOTLY_LOGO = mpimg.imread(\"https://images.plot.ly/logo/new-branding/plotly-logomark.png\")\n",
        "PLOTLY_LOGO = \"https://images.plot.ly/logo/new-branding/plotly-logomark.png\"\n",
        "#PLOTLY_LOGO = \"image/plotly-logomark.png\"\n",
        "with open(\"/content/drive/MyDrive/Dash_plotly_home/precomputed.json\") as precomputed_file:\n",
        "    PRECOMPUTED_LDA = json.load(precomputed_file) \n",
        "#Image(url= \"https://images.plot.ly/logo/new-branding/plotly-logomark.png\")\n",
        "GLOBAL_DF1 = reviews_df\n",
        "\"\"\"\n",
        "We are casting the whole column to datetime to make life easier in the rest of the code.\n",
        "It isn't a terribly expensive operation so for the sake of tidyness we went this way.\n",
        "\"\"\"\n",
        "GLOBAL_DF[\"Date received\"] = pd.to_datetime(\n",
        "    GLOBAL_DF[\"Date received\"], format=\"%m/%d/%Y\"\n",
        ")\n",
        "\n",
        "\"\"\"\n",
        "In order to make the graphs more useful we decided to prevent some words from being included\n",
        "\"\"\"\n",
        "ADDITIONAL_STOPWORDS = [\n",
        "    \"XXXX\",\n",
        "    \"XX\",\n",
        "    \"xx\",\n",
        "    \"xxxx\",\n",
        "    \"n't\",\n",
        "]\n",
        "for stopword in ADDITIONAL_STOPWORDS:\n",
        "    STOPWORDS.add(stopword)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EU7FqdvZOUuI",
        "outputId": "6ae40d88-fbc9-4f89-96e7-8a2ca0f43c2f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n#  Page layout and contents\\nIn an effort to clean up the code a bit, we decided to break it apart into\\nsections. For instance: LEFT_COLUMN is the input controls you see in that gray\\nbox on the top left. The body variable is the overall structure which most other\\nsections go into. This just makes it ever so slightly easier to find the right\\nspot to add to or change without having to count too many brackets.\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 184
        }
      ],
      "source": [
        "def sample_data(dataframe, float_percent):\n",
        "    \"\"\"\n",
        "    Returns a subset of the provided dataframe.\n",
        "    The sampling is evenly distributed and reproducible\n",
        "    \"\"\"\n",
        "    print(\"making a local_df data sample with float_percent: %s\" % (float_percent))\n",
        "    return dataframe.sample(frac=float_percent, random_state=1)\n",
        "\n",
        "\n",
        "def get_complaint_count_by_company(dataframe):\n",
        "    \"\"\" Helper function to get review counts for unique variations \"\"\"\n",
        "    company_counts = dataframe[\"variation\"].value_counts()\n",
        "    # we filter out all banks with less than 11 reviews for now\n",
        "    company_counts = company_counts[company_counts > 10]\n",
        "    values = company_counts.keys().tolist()\n",
        "    counts = company_counts.tolist()\n",
        "    return values, counts\n",
        "\n",
        "\n",
        "def calculate_bank_sample_data(dataframe, sample_size, time_values):\n",
        "    \"\"\" TODO \"\"\"\n",
        "    print(\n",
        "        \"making reviews_sample_data with sample_size count: %s and time_values: %s\"\n",
        "        % (sample_size, time_values)\n",
        "    )\n",
        "    if time_values is not None:\n",
        "        min_date = time_values[0]\n",
        "        max_date = time_values[1]\n",
        "        dataframe = dataframe[\n",
        "            (dataframe[\"Date received\"] >= min_date)\n",
        "            & (dataframe[\"Date received\"] <= max_date)\n",
        "        ]\n",
        "    company_counts = dataframe[\"variation\"].value_counts()\n",
        "    company_counts_sample = company_counts[:sample_size]\n",
        "    values_sample = company_counts_sample.keys().tolist()\n",
        "    counts_sample = company_counts_sample.tolist()\n",
        "\n",
        "    return values_sample, counts_sample\n",
        "\n",
        "\n",
        "def make_local_df(selected_bank, time_values, n_selection):\n",
        "    \"\"\" TODO \"\"\"\n",
        "    print(\"redrawing dataset-wordcloud...\")\n",
        "    n_float = float(n_selection / 100)\n",
        "    print(\"got time window:\", str(time_values))\n",
        "    print(\"got n_selection:\", str(n_selection), str(n_float))\n",
        "    # sample the dataset according to the slider\n",
        "    local_df = sample_data(reviews_df, n_float)\n",
        "    if time_values is not None:\n",
        "        time_values = time_slider_to_date(time_values)\n",
        "        local_df = local_df[\n",
        "            (local_df[\"Date received\"] >= time_values[0])\n",
        "            & (local_df[\"Date received\"] <= time_values[1])\n",
        "        ]\n",
        "    if selected_bank:\n",
        "        local_df = local_df[local_df[\"variation\"] == selected_bank]\n",
        "        \n",
        "    return local_df\n",
        "\n",
        "\n",
        "def make_marks_time_slider(mini, maxi):\n",
        "    \"\"\"\n",
        "    A helper function to generate a dictionary that should look something like:\n",
        "    {1420066800: '2015', 1427839200: 'Q2', 1435701600: 'Q3', 1443650400: 'Q4',\n",
        "    1451602800: '2016', 1459461600: 'Q2', 1467324000: 'Q3', 1475272800: 'Q4',\n",
        "     1483225200: '2017', 1490997600: 'Q2', 1498860000: 'Q3', 1506808800: 'Q4'}\n",
        "    \"\"\"\n",
        "    step = relativedelta.relativedelta(months=+1)\n",
        "    start = datetime(year=mini.year, month=1, day=1)\n",
        "    end = datetime(year=maxi.year, month=maxi.month, day=30)\n",
        "    ret = {}\n",
        "\n",
        "    current = start\n",
        "    while current <= end:\n",
        "        current_str = int(current.timestamp())\n",
        "        if current.month == 1:\n",
        "            ret[current_str] = {\n",
        "                \"label\": str(current.year),\n",
        "                \"style\": {\"font-weight\": \"bold\"},\n",
        "            }\n",
        "        elif current.month == 4:\n",
        "            ret[current_str] = {\n",
        "                \"label\": \"Q2\",\n",
        "                \"style\": {\"font-weight\": \"lighter\", \"font-size\": 7},\n",
        "            }\n",
        "        elif current.month == 7:\n",
        "            ret[current_str] = {\n",
        "                \"label\": \"Q3\",\n",
        "                \"style\": {\"font-weight\": \"lighter\", \"font-size\": 7},\n",
        "            }\n",
        "        elif current.month == 10:\n",
        "            ret[current_str] = {\n",
        "                \"label\": \"Q4\",\n",
        "                \"style\": {\"font-weight\": \"lighter\", \"font-size\": 7},\n",
        "            }\n",
        "        else:\n",
        "            pass\n",
        "        current += step\n",
        "    # print(ret)\n",
        "    return ret\n",
        "\n",
        "\n",
        "def time_slider_to_date(time_values):\n",
        "    \"\"\" TODO \"\"\"\n",
        "    min_date = datetime.fromtimestamp(time_values[0]).strftime(\"%c\")\n",
        "    max_date = datetime.fromtimestamp(time_values[1]).strftime(\"%c\")\n",
        "    print(\"Converted time_values: \")\n",
        "    print(\"\\tmin_date:\", time_values[0], \"to: \", min_date)\n",
        "    print(\"\\tmax_date:\", time_values[1], \"to: \", max_date)\n",
        "    return [min_date, max_date]\n",
        "\n",
        "\n",
        "def make_options_bank_drop(values):\n",
        "    \"\"\"\n",
        "    Helper function to generate the data format the dropdown dash component wants\n",
        "    \"\"\"\n",
        "    ret = []\n",
        "    for value in values:\n",
        "        ret.append({\"label\": value, \"value\": value})\n",
        "    return ret\n",
        "\n",
        "import matplotlib.colors as mcolors\n",
        "def populate_lda_scatter(tsne_df, df_top3words, df_dominant_topic):\n",
        "    \"\"\"Calculates LDA and returns figure data you can jam into a dcc.Graph()\"\"\"\n",
        "    mycolors = np.array([color for name, color in mcolors.TABLEAU_COLORS.items()])\n",
        "\n",
        "    # for each topic we create a separate trace\n",
        "    traces = []\n",
        "    for topic_id in df_top3words[\"topic_id\"]:\n",
        "        tsne_df_f = tsne_df[tsne_df.topic_num == topic_id]\n",
        "        cluster_name = \", \".join(\n",
        "            df_top3words[df_top3words[\"topic_id\"] == topic_id][\"words\"].to_list()\n",
        "        )\n",
        "        trace = go.Scatter(\n",
        "            name=cluster_name,\n",
        "            x=tsne_df_f[\"tsne_x\"],\n",
        "            y=tsne_df_f[\"tsne_y\"],\n",
        "            mode=\"markers\",\n",
        "            hovertext=tsne_df_f[\"doc_num\"],\n",
        "            marker=dict(\n",
        "                size=6,\n",
        "                color=mycolors[tsne_df_f[\"topic_num\"]],  # set color equal to a variable\n",
        "                colorscale=\"Viridis\",\n",
        "                showscale=False,\n",
        "            ),\n",
        "        )\n",
        "        traces.append(trace)\n",
        "\n",
        "    layout = go.Layout({\"title\": \"Topic analysis using LDA\"})\n",
        "\n",
        "    return {\"data\": traces, \"layout\": layout}\n",
        "\n",
        "\n",
        "def plotly_wordcloud(data_frame):\n",
        "    \"\"\"A wonderful function that returns figure data for three equally\n",
        "    wonderful plots: wordcloud, frequency histogram and treemap\"\"\"\n",
        "    complaints_text = list(data_frame[\"verified_reviews\"].dropna().values)\n",
        "\n",
        "    if len(complaints_text) < 1:\n",
        "        return {}, {}, {}\n",
        "\n",
        "    # join all documents in corpus\n",
        "    text = \" \".join(list(complaints_text))\n",
        "\n",
        "    word_cloud = WordCloud(stopwords=set(STOPWORDS), max_words=80, max_font_size=90)\n",
        "    word_cloud.generate(text)\n",
        "\n",
        "    word_list = []\n",
        "    freq_list = []\n",
        "    fontsize_list = []\n",
        "    position_list = []\n",
        "    orientation_list = []\n",
        "    color_list = []\n",
        "\n",
        "    for (word, freq), fontsize, position, orientation, color in word_cloud.layout_:\n",
        "        word_list.append(word)\n",
        "        freq_list.append(freq)\n",
        "        fontsize_list.append(fontsize)\n",
        "        position_list.append(position)\n",
        "        orientation_list.append(orientation)\n",
        "        color_list.append(color)\n",
        "\n",
        "    # get the positions\n",
        "    x_arr = []\n",
        "    y_arr = []\n",
        "    for i in position_list:\n",
        "        x_arr.append(i[0])\n",
        "        y_arr.append(i[1])\n",
        "\n",
        "    # get the relative occurence frequencies\n",
        "    new_freq_list = []\n",
        "    for i in freq_list:\n",
        "        new_freq_list.append(i * 80)\n",
        "\n",
        "    trace = go.Scatter(\n",
        "        x=x_arr,\n",
        "        y=y_arr,\n",
        "        textfont=dict(size=new_freq_list, color=color_list),\n",
        "        hoverinfo=\"text\",\n",
        "        textposition=\"top center\",\n",
        "        hovertext=[\"{0} - {1}\".format(w, f) for w, f in zip(word_list, freq_list)],\n",
        "        mode=\"text\",\n",
        "        text=word_list,\n",
        "    )\n",
        "\n",
        "    layout = go.Layout(\n",
        "        {\n",
        "            \"xaxis\": {\n",
        "                \"showgrid\": False,\n",
        "                \"showticklabels\": False,\n",
        "                \"zeroline\": False,\n",
        "                \"automargin\": True,\n",
        "                \"range\": [-100, 250],\n",
        "            },\n",
        "            \"yaxis\": {\n",
        "                \"showgrid\": False,\n",
        "                \"showticklabels\": False,\n",
        "                \"zeroline\": False,\n",
        "                \"automargin\": True,\n",
        "                \"range\": [-100, 450],\n",
        "            },\n",
        "            \"margin\": dict(t=20, b=20, l=10, r=10, pad=4),\n",
        "            \"hovermode\": \"closest\",\n",
        "        }\n",
        "    )\n",
        "\n",
        "    wordcloud_figure_data = {\"data\": [trace], \"layout\": layout}\n",
        "    word_list_top = word_list[:15]\n",
        "    word_list_top.reverse()\n",
        "    freq_list_top = freq_list[:15]\n",
        "    freq_list_top.reverse()\n",
        "\n",
        "    frequency_figure_data = {\n",
        "        \"data\": [\n",
        "            {\n",
        "                \"y\": word_list_top,\n",
        "                \"x\": freq_list_top,\n",
        "                \"type\": \"bar\",\n",
        "                \"name\": \"\",\n",
        "                \"orientation\": \"h\",\n",
        "            }\n",
        "        ],\n",
        "        \"layout\": {\"height\": \"550\", \"margin\": dict(t=20, b=20, l=100, r=20, pad=4)},\n",
        "    }\n",
        "    treemap_trace = go.Treemap(\n",
        "        labels=word_list_top, parents=[\"\"] * len(word_list_top), values=freq_list_top\n",
        "    )\n",
        "    treemap_layout = go.Layout({\"margin\": dict(t=10, b=10, l=5, r=5, pad=4)})\n",
        "    treemap_figure = {\"data\": [treemap_trace], \"layout\": treemap_layout}\n",
        "    return wordcloud_figure_data, frequency_figure_data, treemap_figure\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "#  Page layout and contents\n",
        "In an effort to clean up the code a bit, we decided to break it apart into\n",
        "sections. For instance: LEFT_COLUMN is the input controls you see in that gray\n",
        "box on the top left. The body variable is the overall structure which most other\n",
        "sections go into. This just makes it ever so slightly easier to find the right\n",
        "spot to add to or change without having to count too many brackets.\n",
        "\"\"\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fk48UdPfPicl"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9fQHS556JCIr"
      },
      "outputs": [],
      "source": [
        "NAVBAR = dbc.Navbar(\n",
        "    children=[\n",
        "        html.A(\n",
        "            # Use row and col to control vertical alignment of logo / brand\n",
        "            dbc.Row(\n",
        "                [\n",
        "                    dbc.Col(html.Img(src=PLOTLY_LOGO,height=\"30px\")),\n",
        "                    dbc.Col(\n",
        "                        dbc.NavbarBrand(\"NLP DASHBOARD for reviews classification\", className=\"ml-2\")\n",
        "                    ),\n",
        "                ],\n",
        "                align=\"center\",\n",
        "                \n",
        "            ),\n",
        "            href=\"https://plot.ly\",\n",
        "        )\n",
        "    ],\n",
        "    color=\"dark\",\n",
        "    dark=True,\n",
        "    sticky=\"top\",\n",
        ")\n",
        "\n",
        "LEFT_COLUMN = dbc.Col(html.Div(\n",
        "    [\n",
        "        html.H4(children=\"Select a variation & dataset size\", className=\"display-5\"),\n",
        "        html.Hr(className=\"my-2\"),\n",
        "        html.Label(\"Select percentage of dataset\", className=\"lead\"),\n",
        "        html.P(\n",
        "            \"(Lower is faster. Higher is more precise)\",\n",
        "            style={\"fontSize\": 10, \"font-weight\": \"lighter\"},\n",
        "        ),\n",
        "        dcc.Slider(\n",
        "            id=\"n-selection-slider\",\n",
        "            min=1,\n",
        "            max=100,\n",
        "            step=1,\n",
        "            marks={\n",
        "                0: \"0%\",\n",
        "                10: \"\",\n",
        "                20: \"20%\",\n",
        "                30: \"\",\n",
        "                40: \"40%\",\n",
        "                50: \"\",\n",
        "                60: \"60%\",\n",
        "                70: \"\",\n",
        "                80: \"80%\",\n",
        "                90: \"\",\n",
        "                100: \"100%\",\n",
        "            },\n",
        "            value=20,\n",
        "        ),\n",
        "        html.Label(\"Select a variation\", style={\"marginTop\": 50}, className=\"lead\"),\n",
        "        html.P(\n",
        "            \"(You can use the dropdown or click the barchart on the right)\",\n",
        "            style={\"fontSize\": 10, \"font-weight\": \"lighter\"},\n",
        "        ),\n",
        "        dcc.Dropdown(\n",
        "            id=\"bank-drop\", clearable=False, style={\"marginBottom\": 50, \"font-size\": 12}\n",
        "        ),\n",
        "        html.Label(\"Select time frame\", className=\"lead\"),\n",
        "        html.Div(dcc.RangeSlider(id=\"time-window-slider\"), style={\"marginBottom\": 50}),\n",
        "        html.P(\n",
        "            \"(You can define the time frame down to month granularity)\",\n",
        "            style={\"fontSize\": 10, \"font-weight\": \"lighter\"},\n",
        "        ),\n",
        "    ])\n",
        ")\n",
        "\n",
        "LDA_PLOT = dcc.Loading(\n",
        "    id=\"loading-lda-plot\", children=[dcc.Graph(id=\"tsne-lda\")], type=\"default\"\n",
        ")\n",
        "LDA_TABLE = html.Div(\n",
        "    id=\"lda-table-block\",\n",
        "    children=[\n",
        "        dcc.Loading(\n",
        "            id=\"loading-lda-table\",\n",
        "            children=[\n",
        "                dash_table.DataTable(\n",
        "                    id=\"lda-table\",\n",
        "                    style_cell_conditional=[\n",
        "                        {\n",
        "                            \"if\": {\"column_id\": \"Text\"},\n",
        "                            \"textAlign\": \"left\",\n",
        "                            \"whiteSpace\": \"normal\",\n",
        "                            \"height\": \"auto\",\n",
        "                            \"min-width\": \"50%\",\n",
        "                        }\n",
        "                    ],\n",
        "                    style_data_conditional=[\n",
        "                        {\n",
        "                            \"if\": {\"row_index\": \"odd\"},\n",
        "                            \"backgroundColor\": \"rgb(243, 246, 251)\",\n",
        "                        }\n",
        "                    ],\n",
        "                    style_cell={\n",
        "                        \"padding\": \"16px\",\n",
        "                        \"whiteSpace\": \"normal\",\n",
        "                        \"height\": \"auto\",\n",
        "                        \"max-width\": \"0\",\n",
        "                    },\n",
        "                    style_header={\"backgroundColor\": \"white\", \"fontWeight\": \"bold\"},\n",
        "                    style_data={\"whiteSpace\": \"normal\", \"height\": \"auto\"},\n",
        "                    filter_action=\"native\",\n",
        "                    page_action=\"native\",\n",
        "                    page_current=0,\n",
        "                    page_size=5,\n",
        "                    columns=[],\n",
        "                    data=[],\n",
        "                )\n",
        "            ],\n",
        "            type=\"default\",\n",
        "        )\n",
        "    ],\n",
        "    style={\"display\": \"none\"},\n",
        ")\n",
        "\n",
        "LDA_PLOTS = [\n",
        "    dbc.CardHeader(html.H5(\"Topic modelling using LDA\")),\n",
        "    dbc.Alert(\n",
        "        \"Not enough data to render LDA plots, please adjust the filters\",\n",
        "        id=\"no-data-alert-lda\",\n",
        "        color=\"warning\",\n",
        "        style={\"display\": \"none\"},\n",
        "    ),\n",
        "    dbc.CardBody(\n",
        "        [\n",
        "            html.P(\n",
        "                \"Click on a review point in the scatter to explore that specific reveiw\",\n",
        "                className=\"mb-0\",\n",
        "            ),\n",
        "            html.P(\n",
        "                \"(not affected by sample size or time frame selection)\",\n",
        "                style={\"fontSize\": 10, \"font-weight\": \"lighter\"},\n",
        "            ),\n",
        "            LDA_PLOT,\n",
        "            html.Hr(),\n",
        "            LDA_TABLE,\n",
        "        ]\n",
        "    ),\n",
        "]\n",
        "WORDCLOUD_PLOTS = [\n",
        "    dbc.CardHeader(html.H5(\"Most frequently used words in reviews\")),\n",
        "    dbc.Alert(\n",
        "        \"Not enough data to render these plots, please adjust the filters\",\n",
        "        id=\"no-data-alert\",\n",
        "        color=\"warning\",\n",
        "        style={\"display\": \"none\"},\n",
        "    ),\n",
        "    dbc.CardBody(\n",
        "        [\n",
        "            dbc.Row(\n",
        "                [\n",
        "                    dbc.Col(\n",
        "                        dcc.Loading(\n",
        "                            id=\"loading-frequencies\",\n",
        "                            children=[dcc.Graph(id=\"frequency_figure\")],\n",
        "                            type=\"default\",\n",
        "                        )\n",
        "                    ),\n",
        "                    dbc.Col(\n",
        "                        [\n",
        "                            dcc.Tabs(\n",
        "                                id=\"tabs\",\n",
        "                                children=[\n",
        "                                    dcc.Tab(\n",
        "                                        label=\"Treemap\",\n",
        "                                        children=[\n",
        "                                            dcc.Loading(\n",
        "                                                id=\"loading-treemap\",\n",
        "                                                children=[dcc.Graph(id=\"bank-treemap\")],\n",
        "                                                type=\"default\",\n",
        "                                            )\n",
        "                                        ],\n",
        "                                    ),\n",
        "                                    dcc.Tab(\n",
        "                                        label=\"Wordcloud\",\n",
        "                                        children=[\n",
        "                                            dcc.Loading(\n",
        "                                                id=\"loading-wordcloud\",\n",
        "                                                children=[\n",
        "                                                    dcc.Graph(id=\"bank-wordcloud\")\n",
        "                                                ],\n",
        "                                                type=\"default\",\n",
        "                                            )\n",
        "                                        ],\n",
        "                                    ),\n",
        "                                ],\n",
        "                            )\n",
        "                        ],\n",
        "                        md=8,\n",
        "                    ),\n",
        "                ]\n",
        "            )\n",
        "        ]\n",
        "    ),\n",
        "]\n",
        "\n",
        "TOP_BANKS_PLOT = [\n",
        "    dbc.CardHeader(html.H5(\"Top variations by number of verified reviews\")),\n",
        "    dbc.CardBody(\n",
        "        [\n",
        "            dcc.Loading(\n",
        "                id=\"loading-banks-hist\",\n",
        "                children=[\n",
        "                    dbc.Alert(\n",
        "                        \"Not enough data to render this plot, please adjust the filters\",\n",
        "                        id=\"no-data-alert-bank\",\n",
        "                        color=\"warning\",\n",
        "                        style={\"display\": \"none\"},\n",
        "                    ),\n",
        "                    dcc.Graph(id=\"bank-sample\"),\n",
        "                ],\n",
        "                type=\"default\",\n",
        "            )\n",
        "        ],\n",
        "        style={\"marginTop\": 0, \"marginBottom\": 0},\n",
        "    ),\n",
        "]\n",
        "\n",
        "TOP_BIGRAM_PLOT = [\n",
        "    dbc.CardHeader(html.H5(\"Top bigrams found in the database\")),\n",
        "    dbc.CardBody(\n",
        "        [\n",
        "            dcc.Loading(\n",
        "                id=\"loading-bigrams-scatter\",\n",
        "                children=[\n",
        "                    dbc.Alert(\n",
        "                        \"Something's gone wrong! Give us a moment, but try loading this page again if problem persists.\",\n",
        "                        id=\"no-data-alert-bigrams\",\n",
        "                        color=\"warning\",\n",
        "                        style={\"display\": \"none\"},\n",
        "                    ),\n",
        "                    dbc.Row(\n",
        "                        [\n",
        "                            dbc.Col(html.P([\"Choose a t-SNE perplexity value:\"]), md=6),\n",
        "                            dbc.Col(\n",
        "                                [\n",
        "                                    dcc.Dropdown(\n",
        "                                        id=\"bigrams-perplex-dropdown\",\n",
        "                                        options=[\n",
        "                                            {\"label\": str(i), \"value\": i}\n",
        "                                            for i in range(3, 7)\n",
        "                                        ],\n",
        "                                        value=3,\n",
        "                                    )\n",
        "                                ],\n",
        "                                md=3,\n",
        "                            ),\n",
        "                        ]\n",
        "                    ),\n",
        "                    dcc.Graph(id=\"bigrams-scatter\"),\n",
        "                ],\n",
        "                type=\"default\",\n",
        "            )\n",
        "        ],\n",
        "        style={\"marginTop\": 0, \"marginBottom\": 0},\n",
        "    ),\n",
        "]\n",
        "\n",
        "TOP_BIGRAM_COMPS = [\n",
        "    dbc.CardHeader(html.H5(\"Comparison of bigrams for two variations\")),\n",
        "    dbc.CardBody(\n",
        "        [\n",
        "            dcc.Loading(\n",
        "                id=\"loading-bigrams-comps\",\n",
        "                children=[\n",
        "                    dbc.Alert(\n",
        "                        \"Something's gone wrong! Give us a moment, but try loading this page again if problem persists.\",\n",
        "                        id=\"no-data-alert-bigrams_comp\",\n",
        "                        color=\"warning\",\n",
        "                        style={\"display\": \"none\"},\n",
        "                    ),\n",
        "                    dbc.Row(\n",
        "                        [\n",
        "                            dbc.Col(html.P(\"Choose two variations to compare:\"), md=12),\n",
        "                            dbc.Col(\n",
        "                                [\n",
        "                                    dcc.Dropdown(\n",
        "                                        id=\"bigrams-comp_1\",\n",
        "                                        options=[\n",
        "                                            {\"label\": i, \"value\": i}\n",
        "                                            for i in bigram_df.company.unique()\n",
        "                                        ],\n",
        "                                        value=\"Charcoal Fabric\",\n",
        "                                    )\n",
        "                                ],\n",
        "                                md=6,\n",
        "                            ),\n",
        "                            dbc.Col(\n",
        "                                [\n",
        "                                    dcc.Dropdown(\n",
        "                                        id=\"bigrams-comp_2\",\n",
        "                                        options=[\n",
        "                                            {\"label\": i, \"value\": i}\n",
        "                                            for i in bigram_df.company.unique()\n",
        "                                        ],\n",
        "                                        value=\"Heather Gray Fabric\",\n",
        "                                    )\n",
        "                                ],\n",
        "                                md=6,\n",
        "                            ),\n",
        "                        ]\n",
        "                    ),\n",
        "                    dcc.Graph(id=\"bigrams-comps\"),\n",
        "                ],\n",
        "                type=\"default\",\n",
        "            )\n",
        "        ],\n",
        "        style={\"marginTop\": 0, \"marginBottom\": 0},\n",
        "    ),\n",
        "]\n",
        "\n",
        "\n",
        "PRED =  dbc.Container(\n",
        "        \n",
        "        dbc.Row(\n",
        "                [\n",
        "                    html.H1(id = 'heading', children = \"Reviews prediction with ML\", className = 'display-3 mb-4'),\n",
        "                    html.H3(id = 'heading_pie', children = 'Select a review to get its predicted sentiment :',className = 'display-6 mb-7',\n",
        "                            style = {'margin-top': '30px','margin-bottom': '15px'}),\n",
        "                    \n",
        "                    dbc.Container([\n",
        "                            dcc.Dropdown(\n",
        "                    id='dropdown',\n",
        "                    placeholder = 'Select a Review',\n",
        "                    options=[{'label': i[:60] + \"...\", 'value': i} for i in reviews_df.verified_reviews[:1000]],\n",
        "                    value = reviews_df.verified_reviews[0],\n",
        "                    style = {'margin-bottom': '30px'}\n",
        "                    \n",
        "                )\n",
        "                       ],\n",
        "                        style = {'padding-left': '50px', 'padding-right': '50px'}\n",
        "                        ),\n",
        "                    dbc.Button(\"Submit\", color=\"dark\", className=\"mt-2 mb-3\", id = 'button', style = {'width': '100px'}),\n",
        "                    dbc.Row([html.Div(id='result1')]),\n",
        "                    dbc.Textarea(id = 'textarea', className=\"mb-3\", placeholder=\"Enter the Review\", value = '', style={'width': '100%', 'height': 100}),\n",
        "                    dbc.Button(\"Submit\", color=\"dark\", className=\"mt-2 mb-3\", id = 'button_2', style = {'width': '100px'}),\n",
        "                    dbc.Row([html.Div(id='result')])\n",
        "                    ],\n",
        "                className = 'text-center'\n",
        "                ),\n",
        "        className = 'mt-4'\n",
        "        )\n",
        "\n",
        "\n",
        "BODY = dbc.Container(\n",
        "    [\n",
        "        dbc.Row([dbc.Col(dbc.Card(TOP_BIGRAM_COMPS)),], style={\"marginTop\": 30}),\n",
        "        dbc.Row([dbc.Col(dbc.Card(TOP_BIGRAM_PLOT)),], style={\"marginTop\": 30}),\n",
        "        dbc.Row(\n",
        "            [\n",
        "                dbc.Col(LEFT_COLUMN, md=4, align=\"center\"),\n",
        "                dbc.Col(dbc.Card(TOP_BANKS_PLOT), md=8),\n",
        "            ],\n",
        "            style={\"marginTop\": 30},\n",
        "        ),\n",
        "        dbc.Card(WORDCLOUD_PLOTS),\n",
        "        dbc.Row([dbc.Col([dbc.Card(LDA_PLOTS)])], style={\"marginTop\": 50}),\n",
        "     \n",
        "    ],\n",
        "    className=\"mt-12\",\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://towardsdatascience.com/creating-an-interactive-data-app-using-plotlys-dash-356428b4699c"
      ],
      "metadata": {
        "id": "vMzr_Qz4VT-X"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        },
        "id": "L-tOa1xjaS87",
        "outputId": "1d9c1216-5f7e-41ea-e2ac-2c799504677e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'    value=\\'Its like Siri, in fact, Siri answers more accurately then Alexa.  I dont see a real need for it in my household, though it was a good bargain on prime day deals.\\'\\n    transformer = TfidfTransformer()\\n    loaded_vec = CountVectorizer(decode_error=\"replace\",vocabulary=vocab)\\n    value = transformer.fit_transform(loaded_vec.fit_transform([value]))\\n    file = open(\"/content/drive/MyDrive/Dash_plotly_home/trained_model.pkl\", \\'rb\\')\\n    pickle_model = pickle.load(file)\\n    result_list = pickle_model.predict(value)\\n  \\n    if (result_list == 0 ):\\n      result1t=\\'Negative\\'\\n            \\n    elif (result_list == 1 ):\\n      result1=\\'Positive\\'\\n    \\n    print(f\\'the review is {result1}\\')'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 186
        }
      ],
      "source": [
        "\"\"\"    value='Its like Siri, in fact, Siri answers more accurately then Alexa.  I dont see a real need for it in my household, though it was a good bargain on prime day deals.'\n",
        "    transformer = TfidfTransformer()\n",
        "    loaded_vec = CountVectorizer(decode_error=\"replace\",vocabulary=vocab)\n",
        "    value = transformer.fit_transform(loaded_vec.fit_transform([value]))\n",
        "    file = open(\"/content/drive/MyDrive/Dash_plotly_home/trained_model.pkl\", 'rb')\n",
        "    pickle_model = pickle.load(file)\n",
        "    result_list = pickle_model.predict(value)\n",
        "  \n",
        "    if (result_list == 0 ):\n",
        "      result1t='Negative'\n",
        "            \n",
        "    elif (result_list == 1 ):\n",
        "      result1='Positive'\n",
        "    \n",
        "    print(f'the review is {result1}')\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import base64\n",
        "import plotly.graph_objs as go\n",
        "import cufflinks as cf\n",
        "import dash\n",
        "import io \n",
        "from dash.dependencies import Input, Output, State\n",
        "import dash_core_components as dcc\n",
        "import dash_html_components as html\n",
        "import dash_table"
      ],
      "metadata": {
        "id": "X2G0nQ_wAVt-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qKGASntOOr0v"
      },
      "outputs": [],
      "source": [
        "app.layout = html.Div(children=[NAVBAR, BODY,PRED,UPLOAD])\n",
        "\n",
        "\"\"\"\n",
        "#  Callbacks\n",
        "\"\"\"\n",
        "@app.callback(\n",
        "    Output('result', 'children'),\n",
        "    [\n",
        "    Input('button_2', 'n_clicks')\n",
        "    ],\n",
        "    [\n",
        "    State('textarea', 'value')\n",
        "    ]\n",
        "    )    \n",
        "def update_app_ui(n_clicks, textarea):\n",
        "    transformer = TfidfTransformer()\n",
        "    loaded_vec = CountVectorizer(decode_error=\"replace\",vocabulary=vocab)\n",
        "    textarea = transformer.fit_transform(loaded_vec.fit_transform([textarea]))\n",
        "    file = open(\"/content/drive/MyDrive/Dash_plotly_home/trained_model.pkl\", 'rb')\n",
        "    pickle_model = pickle.load(file)\n",
        "    result_list = pickle_model.predict(textarea)\n",
        "    if n_clicks >0:\n",
        "        if (result_list == 0 ):\n",
        "          result='Negative'\n",
        "            \n",
        "        elif (result_list == 1 ):\n",
        "            result='Positive'\n",
        "    return f'the review is {result}'    \n",
        "\n",
        "@app.callback(\n",
        "    Output('result1', 'children'),\n",
        "    [\n",
        "    Input('button', 'n_clicks')\n",
        "    ],\n",
        "    [\n",
        "    State('dropdown', 'value')\n",
        "     ]\n",
        "    )\n",
        "def update_dropdown(n_clicks, value):\n",
        "    transformer = TfidfTransformer()\n",
        "    loaded_vec = CountVectorizer(decode_error=\"replace\",vocabulary=vocab)\n",
        "    value = transformer.fit_transform(loaded_vec.fit_transform([value]))\n",
        "    file = open(\"/content/drive/MyDrive/Dash_plotly_home/trained_model.pkl\", 'rb')\n",
        "    pickle_model = pickle.load(file)\n",
        "    result_list = pickle_model.predict(value)\n",
        "    if n_clicks >0:\n",
        "        if (result_list == 0 ):\n",
        "          result1='Negative'\n",
        "            \n",
        "        elif (result_list == 1 ):\n",
        "            result1='Positive'\n",
        "    return f'the review is {result1}' \n",
        "\n",
        "\n",
        "@app.callback(\n",
        "    Output(\"bigrams-scatter\", \"figure\"), [Input(\"bigrams-perplex-dropdown\", \"value\")],\n",
        ")\n",
        "def populate_bigram_scatter(perplexity):\n",
        "    X_embedded = TSNE(n_components=2, perplexity=perplexity).fit_transform(vects_df)\n",
        "\n",
        "    embed_df[\"tsne_1\"] = X_embedded[:, 0]\n",
        "    embed_df[\"tsne_2\"] = X_embedded[:, 1]\n",
        "    fig = px.scatter(\n",
        "        embed_df,\n",
        "        x=\"tsne_1\",\n",
        "        y=\"tsne_2\",\n",
        "        hover_name=\"bigram\",\n",
        "        text=\"bigram\",\n",
        "        size=\"count\",\n",
        "        color=\"words\",\n",
        "        size_max=45,\n",
        "        template=\"plotly_white\",\n",
        "        title=\"Bigram similarity and frequency\",\n",
        "        labels={\"words\": \"Count<BR>(words)\"},\n",
        "        color_continuous_scale=px.colors.sequential.Sunsetdark,\n",
        "    )\n",
        "    fig.update_traces(marker=dict(line=dict(width=1, color=\"Gray\")))\n",
        "    fig.update_xaxes(visible=False)\n",
        "    fig.update_yaxes(visible=False)\n",
        "    return fig\n",
        "\n",
        "\n",
        "@app.callback(\n",
        "    Output(\"bigrams-comps\", \"figure\"),\n",
        "    [Input(\"bigrams-comp_1\", \"value\"), Input(\"bigrams-comp_2\", \"value\")],\n",
        ")\n",
        "def comp_bigram_comparisons(comp_first, comp_second):\n",
        "    comp_list = [comp_first, comp_second]\n",
        "    temp_df = bigram_df[bigram_df.company.isin(comp_list)]\n",
        "    temp_df.loc[temp_df.company == comp_list[-1], \"value\"] = -temp_df[\n",
        "        temp_df.company == comp_list[-1]\n",
        "    ].value.values\n",
        "\n",
        "    fig = px.bar(\n",
        "        temp_df,\n",
        "        title=\"Comparison: \" + comp_first + \" | \" + comp_second,\n",
        "        x=\"ngram\",\n",
        "        y=\"value\",\n",
        "        color=\"company\",\n",
        "        template=\"plotly_white\",\n",
        "        color_discrete_sequence=px.colors.qualitative.Bold,\n",
        "        labels={\"company\": \"variat°:\", \"ngram\": \"N-Gram\"},\n",
        "        hover_data=\"\",\n",
        "    )\n",
        "    fig.update_layout(legend=dict(x=0.1, y=1.1), legend_orientation=\"h\")\n",
        "    fig.update_yaxes(title=\"\", showticklabels=False)\n",
        "    fig.data[0][\"hovertemplate\"] = fig.data[0][\"hovertemplate\"][:-14]\n",
        "    return fig\n",
        "\n",
        "\n",
        "@app.callback(\n",
        "    [\n",
        "        Output(\"time-window-slider\", \"marks\"),\n",
        "        Output(\"time-window-slider\", \"min\"),\n",
        "        Output(\"time-window-slider\", \"max\"),\n",
        "        Output(\"time-window-slider\", \"step\"),\n",
        "        Output(\"time-window-slider\", \"value\"),\n",
        "    ],\n",
        "    [Input(\"n-selection-slider\", \"value\")],\n",
        ")\n",
        "def populate_time_slider(value):\n",
        "    \"\"\"\n",
        "    Depending on our dataset, we need to populate the time-slider\n",
        "    with different ranges. This function does that and returns the\n",
        "    needed data to the time-window-slider.\n",
        "    \"\"\"\n",
        "    value += 0\n",
        "    min_date = reviews_df[\"Date received\"].min()\n",
        "    max_date = reviews_df[\"Date received\"].max()\n",
        "\n",
        "    marks = make_marks_time_slider(min_date, max_date)\n",
        "    min_epoch = list(marks.keys())[0]\n",
        "    max_epoch = list(marks.keys())[-1]\n",
        "\n",
        "    return (\n",
        "        marks,\n",
        "        min_epoch,\n",
        "        max_epoch,\n",
        "        (max_epoch - min_epoch) / (len(list(marks.keys())) * 3),\n",
        "        [min_epoch, max_epoch],\n",
        "    )\n",
        "\n",
        "\n",
        "@app.callback(\n",
        "    Output(\"bank-drop\", \"options\"),\n",
        "    [Input(\"time-window-slider\", \"value\"), Input(\"n-selection-slider\", \"value\")],\n",
        ")\n",
        "def populate_bank_dropdown(time_values, n_value):\n",
        "    \"\"\" TODO \"\"\"\n",
        "    print(\"variation-drop: TODO USE THE TIME VALUES AND N-SLIDER TO LIMIT THE DATASET\")\n",
        "    if time_values is not None:\n",
        "        pass\n",
        "    n_value += 1\n",
        "    bank_names, counts = get_complaint_count_by_company(reviews_df)\n",
        "    counts.append(1)\n",
        "    return make_options_bank_drop(bank_names)\n",
        "\n",
        "\n",
        "@app.callback(\n",
        "    [Output(\"bank-sample\", \"figure\"), Output(\"no-data-alert-bank\", \"style\")],\n",
        "    [Input(\"n-selection-slider\", \"value\"), Input(\"time-window-slider\", \"value\")],\n",
        ")\n",
        "def update_bank_sample_plot(n_value, time_values):\n",
        "    \"\"\" TODO \"\"\"\n",
        "    print(\"redrawing variation-sample...\")\n",
        "    print(\"\\tn is:\", n_value)\n",
        "    print(\"\\ttime_values is:\", time_values)\n",
        "    if time_values is None:\n",
        "        return [{}, {\"display\": \"block\"}]\n",
        "    n_float = float(n_value / 100)\n",
        "    bank_sample_count = 10\n",
        "    local_df = sample_data(reviews_df, n_float)\n",
        "    min_date, max_date = time_slider_to_date(time_values)\n",
        "    values_sample, counts_sample = calculate_bank_sample_data(\n",
        "        local_df, bank_sample_count, [min_date, max_date]\n",
        "    )\n",
        "    data = [\n",
        "        {\n",
        "            \"x\": values_sample,\n",
        "            \"y\": counts_sample,\n",
        "            \"text\": values_sample,\n",
        "            \"textposition\": \"auto\",\n",
        "            \"type\": \"bar\",\n",
        "            \"name\": \"\",\n",
        "        }\n",
        "    ]\n",
        "    layout = {\n",
        "        \"autosize\": False,\n",
        "        \"margin\": dict(t=10, b=10, l=40, r=0, pad=4),\n",
        "        \"xaxis\": {\"showticklabels\": False},\n",
        "    }\n",
        "    print(\"redrawing variation-sample...done\")\n",
        "    return [{\"data\": data, \"layout\": layout}, {\"display\": \"none\"}]\n",
        "\n",
        "\n",
        "@app.callback(\n",
        "    [\n",
        "        Output(\"lda-table\", \"data\"),\n",
        "        Output(\"lda-table\", \"columns\"),\n",
        "        Output(\"tsne-lda\", \"figure\"),\n",
        "        Output(\"no-data-alert-lda\", \"style\"),\n",
        "    ],\n",
        "    [Input(\"bank-drop\", \"value\"), Input(\"time-window-slider\", \"value\")],\n",
        ")\n",
        "def update_lda_table(selected_bank, time_values):\n",
        "    \"\"\" Update LDA table and scatter plot based on precomputed data \"\"\"\n",
        "\n",
        "    if selected_bank in PRECOMPUTED_LDA:\n",
        "        df_dominant_topic = pd.read_json(\n",
        "            PRECOMPUTED_LDA[selected_bank][\"df_dominant_topic\"]\n",
        "        )\n",
        "        tsne_df = pd.read_json(PRECOMPUTED_LDA[selected_bank][\"tsne_df\"])\n",
        "        df_top3words = pd.read_json(PRECOMPUTED_LDA[selected_bank][\"df_top3words\"])\n",
        "    else:\n",
        "        return [[], [], {}, {}]\n",
        "\n",
        "    lda_scatter_figure = populate_lda_scatter(tsne_df, df_top3words, df_dominant_topic)\n",
        "\n",
        "    columns = [{\"name\": i, \"id\": i} for i in df_dominant_topic.columns]\n",
        "    data = df_dominant_topic.to_dict(\"records\")\n",
        "\n",
        "    return (data, columns, lda_scatter_figure, {\"display\": \"none\"})\n",
        "\n",
        "\n",
        "@app.callback(\n",
        "    [\n",
        "        Output(\"bank-wordcloud\", \"figure\"),\n",
        "        Output(\"frequency_figure\", \"figure\"),\n",
        "        Output(\"bank-treemap\", \"figure\"),\n",
        "        Output(\"no-data-alert\", \"style\"),\n",
        "    ],\n",
        "    [\n",
        "        Input(\"bank-drop\", \"value\"),\n",
        "        Input(\"time-window-slider\", \"value\"),\n",
        "        Input(\"n-selection-slider\", \"value\"),\n",
        "    ],\n",
        ")\n",
        "def update_wordcloud_plot(value_drop, time_values, n_selection):\n",
        "    \"\"\" Callback to rerender wordcloud plot \"\"\"\n",
        "    local_df = make_local_df(value_drop, time_values, n_selection)\n",
        "    wordcloud, frequency_figure, treemap = plotly_wordcloud(local_df)\n",
        "    alert_style = {\"display\": \"none\"}\n",
        "    if (wordcloud == {}) or (frequency_figure == {}) or (treemap == {}):\n",
        "        alert_style = {\"display\": \"block\"}\n",
        "    print(\"redrawing variation wordcloud...done\")\n",
        "    return (wordcloud, frequency_figure, treemap, alert_style)\n",
        "\n",
        "\n",
        "@app.callback(\n",
        "    [Output(\"lda-table\", \"filter_query\"), Output(\"lda-table-block\", \"style\")],\n",
        "    [Input(\"tsne-lda\", \"clickData\")],\n",
        "    [State(\"lda-table\", \"filter_query\")],\n",
        ")\n",
        "def filter_table_on_scatter_click(tsne_click, current_filter):\n",
        "    \"\"\" TODO \"\"\"\n",
        "    if tsne_click is not None:\n",
        "        selected_complaint = tsne_click[\"points\"][0][\"hovertext\"]\n",
        "        if current_filter != \"\":\n",
        "            filter_query = (\n",
        "                \"({Document_No} eq \"\n",
        "                + str(selected_complaint)\n",
        "                + \") || (\"\n",
        "                + current_filter\n",
        "                + \")\"\n",
        "            )\n",
        "        else:\n",
        "            filter_query = \"{Document_No} eq \" + str(selected_complaint)\n",
        "        print(\"current_filter\", current_filter)\n",
        "        return (filter_query, {\"display\": \"block\"})\n",
        "    return [\"\", {\"display\": \"none\"}]\n",
        "\n",
        "\n",
        "@app.callback(Output(\"bank-drop\", \"value\"), [Input(\"bank-sample\", \"clickData\")])\n",
        "def update_bank_drop_on_click(value):\n",
        "    \"\"\" TODO \"\"\"\n",
        "    if value is not None:\n",
        "        selected_bank = value[\"points\"][0][\"x\"]\n",
        "        return selected_bank\n",
        "    return \"Charcoal Fabric\"\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "u7fiQr2KuSHL",
        "outputId": "9a5c7a4e-25e4-415c-efa2-ae8b6b7d799c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dash app running on:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "(async (port, path, text, element) => {\n",
              "    if (!google.colab.kernel.accessAllowed) {\n",
              "      return;\n",
              "    }\n",
              "    element.appendChild(document.createTextNode(''));\n",
              "    const url = await google.colab.kernel.proxyPort(port);\n",
              "    const anchor = document.createElement('a');\n",
              "    anchor.href = new URL(path, url).toString();\n",
              "    anchor.target = '_blank';\n",
              "    anchor.setAttribute('data-href', url + path);\n",
              "    anchor.textContent = text;\n",
              "    element.appendChild(anchor);\n",
              "  })(8050, \"/\", \"http://127.0.0.1:8050/\", window.element)"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "if __name__ == \"__main__\":\n",
        "    #app.run_server(mode= 'inline')\n",
        "    app.run_server(debug=True ,use_reloader=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 109
        },
        "id": "vY49D-M7miLx",
        "outputId": "61737a89-24ae-4bc0-d5f6-d7088e808cd8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'embed_df.to_csv(\\'/content/drive/MyDrive/Dash_plotly_home/embed_df_n.csv\\',index = False)\\nfiles.download(\\'/content/drive/MyDrive/Dash_plotly_home/embed_df_n.csv\\')\\n!cp -r \"/content/drive/MyDrive/Dash_plotly_home/embed_df_n.csv\" \"/content/drive/MyDrive/Dash_plotly_home/\"\\n\\nbigram_df.to_csv(\\'/content/drive/MyDrive/Dash_plotly_home/bigram_df_n.csv\\',index = False)\\nfiles.download(\\'/content/drive/MyDrive/Dash_plotly_home/bigram_df_n.csv\\')\\n!cp -r \"/content/drive/MyDrive/Dash_plotly_home/bigram_df_n.csv\" \"/content/drive/MyDrive/Dash_plotly_home/'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 190
        }
      ],
      "source": [
        "\n",
        "\"\"\"embed_df.to_csv('/content/drive/MyDrive/Dash_plotly_home/embed_df_n.csv',index = False)\n",
        "files.download('/content/drive/MyDrive/Dash_plotly_home/embed_df_n.csv')\n",
        "!cp -r \"/content/drive/MyDrive/Dash_plotly_home/embed_df_n.csv\" \"/content/drive/MyDrive/Dash_plotly_home/\"\n",
        "\n",
        "bigram_df.to_csv('/content/drive/MyDrive/Dash_plotly_home/bigram_df_n.csv',index = False)\n",
        "files.download('/content/drive/MyDrive/Dash_plotly_home/bigram_df_n.csv')\n",
        "!cp -r \"/content/drive/MyDrive/Dash_plotly_home/bigram_df_n.csv\" \"/content/drive/MyDrive/Dash_plotly_home/\"\"\""
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.9.7 ('base')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "vscode": {
      "interpreter": {
        "hash": "ad88f0db3467f5864ea1db9ef7250ec56abf639c4f9456de0b73450094059d1d"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}